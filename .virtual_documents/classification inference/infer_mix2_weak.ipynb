import torch
from torch import nn
from torchvision import transforms
from torchvision import models
from torchsummary import summary
import matplotlib.pyplot as plt
from PIL import Image
from PIL import ImageFilter
from PIL import ImageOps
from torch.utils.data import Dataset
from torch.utils.data import DataLoader
from torch.utils.data import random_split
from torch.optim.lr_scheduler import ReduceLROnPlateau
from copy import copy
from copy import deepcopy
import sys
import os
import pandas as pd
import numpy as np
import random
from pathlib import Path

os.environ['KMP_DUPLICATE_LIB_OK'] = 'True' # dead kernel for matplotlib


device = 'cuda' if torch.cuda.is_available() else 'cpu'
print(device)


metadata = pd.read_csv('../doby_meta.csv')
metadata.info()


metadata = metadata[metadata['subject_id'] < 16000000]
metadata.info()


SEG_BASE_PATH = '../chest-x-ray-dataset-with-lung-segmentation-1.0.0/chest-x-ray-dataset-with-lung-segmentation-1.0.0'
ORIG_BASE_PATH = '../physionet.org/files/mimic-cxr-jpg/2.0.0'


class Resize(object):
    def __init__(self, size):
        self.size = size

    def __call__(self, x_seg, x_orig):
        return x_seg, x_orig.resize((self.size, self.size))

class MixImage(object):
    def __call__(self, fore, back):
        back.paste(fore, (0, 0), fore)
        return back

TRANSFORMS = transforms.Compose([
    transforms.ToTensor()
])


class Dataset(Dataset):
    def __init__(self, metadata, seg_base_path, orig_base_path, transform=None):
        self.metadata = metadata
        self.seg_base_path = Path(seg_base_path)
        self.orig_base_path = Path(orig_base_path)
        self.transform = transform

    def __getitem__(self, idx):
        x_path = self.metadata.loc[idx, 'DicomPath']
        x_seg_path = self.seg_base_path / Path(x_path)
        x_orig_path = self.orig_base_path / Path(x_path)
        
        x_seg = Image.open(x_seg_path).convert('L') # convert를 하지 않으면, ToTensor를 할 때, 3x224x224로 바꾼다.
        x_orig = Image.open(x_orig_path).convert('L').resize(x_seg.size)

        '''
        plt.subplot(2, 2, 1)
        plt.imshow(x_orig, cmap='gray')
        plt.axis('off')
                    
        plt.subplot(2, 2, 2)
        plt.imshow(x_seg, cmap='gray')
        plt.axis('off')
        '''

        # radius 1에서 0.5로 조정
        x_orig = x_orig.filter(ImageFilter.GaussianBlur(0.5))

        '''
        plt.subplot(2, 2, 3)
        plt.imshow(x_orig, cmap='gray')
        plt.axis('off')
        '''

        # 0.2에서 0.1로
        x_mix = Image.blend(x_orig, x_seg, 0.1)

        # Histogram Equalization
        x_mix = ImageOps.equalize(x_mix)

        '''
        plt.subplot(2, 2, 4)
        plt.imshow(x_mix, cmap='gray')
        plt.axis('off')
        plt.show()
        '''
        
        y = self.metadata.loc[idx, 'normal']

        if self.transform:
            x = self.transform(x_mix)

        return x, y

    def __len__(self):
        return self.metadata['normal'].count()


ds = Dataset(metadata, SEG_BASE_PATH, ORIG_BASE_PATH, transform=TRANSFORMS)


ds_size = len(ds)
train_size = int(ds_size * 0.8)
test_size = ds_size - train_size
train_ds, test_ds = random_split(ds, [train_size, test_size], generator=torch.manual_seed(42))


len(test_ds)


test_dl = DataLoader(test_ds, batch_size=8, shuffle=True)


class customDenseNet(nn.Module):
    def __init__(self):
        super(customDenseNet, self).__init__()
        self.model = models.densenet121()
        self.model.features.conv0 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)
        self.linear = nn.Linear(1000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.model(x)
        x = self.linear(x)
        x = self.sigmoid(x)

        return x


PATH = '../classification/densenet_parameters/mix_weak_best_acc_model_state.pt'
model = customDenseNet()
model.load_state_dict(torch.load(PATH))
model.to(device)

PATH2 = '../classification/densenet_parameters/mix_weak_best_f1_model_state.pt'
model2 = customDenseNet()
model2.load_state_dict(torch.load(PATH2))
model2.to(device)


weights = (metadata['normal'] == 1).sum() / (metadata['normal'] == 0).sum()
loss_fn = nn.BCEWithLogitsLoss(pos_weight=torch.Tensor([weights])).to(device)


def getMetric(TP, FP, TN, FN):
    # base case: divide by zero
    TP = 0.1 if TP == 0 else TP
    FP = 0.1 if FP == 0 else FP
    TN = 0.1 if TN == 0 else TN
    FN = 0.1 if FN == 0 else FN
    
    sensitivity = TP/(TP+FN)
    specificity = TN/(TN+FP)
    precision = TP/(TP+FP)
    recall = TP/(TP+FN)
    f1_score = 2*precision*recall/(precision+recall)
    return sensitivity, specificity, f1_score


def test(model, data_loader):
    model.eval()
    test_acc = 0
    test_loss = 0
    n_data = 0
    TP, FP, TN, FN = 0, 0, 0, 0
    pre = []
    tar = []
    
    with torch.no_grad():
        for batch, target in data_loader:
            batch, target = batch.to(device), target.to(device)

            output = model(batch)
            target = target.unsqueeze(dim=-1).float()
            temp_pre = output.cpu().detach().numpy()
            pre.append(temp_pre)
            temp_tar = target.cpu().detach().numpy()
            tar.append(temp_tar)

            loss = loss_fn(output, target)
            test_loss += loss.item()

            predicted = (output >= torch.FloatTensor([0.5]).to(device)).type(torch.float32)
            correct = (predicted == target).sum().item()
            test_acc += correct

            TP += ((predicted == target) & (target == 1)).sum().item()
            FP += ((predicted != target) & (target == 0)).sum().item()
            TN += ((predicted == target) & (target == 0)).sum().item()
            FN += ((predicted != target) & (target == 1)).sum().item()
            
            n_data += len(batch)
            print(f'\rTest set: [{100*n_data/len(data_loader.dataset):.2f}%]', end='')
    
    test_acc = 100 * test_acc / len(data_loader.dataset)
    test_loss = test_loss / len(data_loader)
    
    print(f'\rTest set: Accuracy: {test_acc:.2f}%  Loss: {test_loss:.4f}')

    return test_acc, test_loss, TP, FP, TN, FN, pre, tar


acc, loss, tp, fp, tn, fn, pre, tar = test(model, test_dl)
sensitivity, specificity, f1_score = getMetric(tp, fp, tn, fn)
print(f'TP: {tp}, FP: {fp}, TN: {tn}, FN: {fn}')
print(f'Sensitivity: {sensitivity:.4f}, Specificity: {specificity:.4f}, F1-Score: {f1_score:.4f}')


from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score

pre = np.array(pre).flatten()
tar = np.array(tar).flatten()
fpr, tpr, thresholds = roc_curve(tar, pre)

plt.plot(fpr, tpr)
plt.plot([0, 1], [0, 1])
print(f'AUC: {roc_auc_score(tar, pre):.4f}')


np.save('./target_and_predict/mix_weak_acc_tar', tar)
np.save('./target_and_predict/mix_weak_acc_pre', pre)


acc, loss, tp, fp, tn, fn, pre, tar = test(model2, test_dl)
sensitivity, specificity, f1_score = getMetric(tp, fp, tn, fn)
print(f'TP: {tp}, FP: {fp}, TN: {tn}, FN: {fn}')
print(f'Sensitivity: {sensitivity:.4f}, Specificity: {specificity:.4f}, F1-Score: {f1_score:.4f}')


pre = np.array(pre).flatten()
tar = np.array(tar).flatten()
fpr, tpr, thresholds = roc_curve(tar, pre)

plt.plot(fpr, tpr)
plt.plot([0, 1], [0, 1])
print(f'AUC: {roc_auc_score(tar, pre):.4f}')


np.save('./target_and_predict/mix_weak_f1_tar', tar)
np.save('./target_and_predict/mix_weak_f1_pre', pre)
