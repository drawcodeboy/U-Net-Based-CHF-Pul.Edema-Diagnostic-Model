import torch
from torch import nn
from torchvision import transforms
from torchvision import models
import matplotlib.pyplot as plt
from PIL import Image
from PIL import ImageFilter
from PIL import ImageOps
from torch.utils.data import Dataset
from torch.utils.data import DataLoader
from torch.utils.data import random_split
from torch.optim.lr_scheduler import ReduceLROnPlateau
from copy import copy
from copy import deepcopy
import cv2
import sys
import os
import pandas as pd
import numpy as np
import random
from pathlib import Path

os.environ['KMP_DUPLICATE_LIB_OK'] = 'True' # dead kernel for matplotlib


device = 'cuda' if torch.cuda.is_available() else 'cpu'
print(device)


metadata = pd.read_csv('../doby_meta.csv')
metadata.info()


metadata = pd.read_csv('../doby_meta.csv')
metadata.info()


metadata = metadata[metadata['subject_id'] < 16000000]
metadata.info()


metadata = metadata[metadata['subject_id'] < 16000000]
metadata.info()


SEG_BASE_PATH = '../chest-x-ray-dataset-with-lung-segmentation-1.0.0/chest-x-ray-dataset-with-lung-segmentation-1.0.0'
ORIG_BASE_PATH = '../physionet.org/files/mimic-cxr-jpg/2.0.0'


MERGE_TRANSFORMS = transforms.Compose([
    transforms.ToTensor()
])


class Dataset(Dataset):
    def __init__(self, metadata, seg_base_path, orig_base_path, transform=None):
        self.metadata = metadata
        self.seg_base_path = Path(seg_base_path)
        self.orig_base_path = Path(orig_base_path)
        self.transform = transform

    def __getitem__(self, idx):
        x_path = self.metadata.loc[idx, 'DicomPath']
        x_seg_mask_path = self.seg_base_path / Path(x_path[:-4] + '-mask.jpg')
        x_seg_path = self.seg_base_path / Path(x_path)
        x_orig_path = self.orig_base_path / Path(x_path)

        x_seg = cv2.imread(str(x_seg_path), cv2.IMREAD_GRAYSCALE)
        x_seg_mask = cv2.imread(str(x_seg_mask_path), cv2.IMREAD_GRAYSCALE)
        x_orig = cv2.imread(str(x_orig_path), cv2.IMREAD_GRAYSCALE)
        x_orig = cv2.resize(x_orig, dsize=(224, 224), interpolation=cv2.INTER_AREA)

        # 노이즈 제거
        seg_mask1 = np.where(x_seg_mask > 128, 1, 0) # 128 threshold
        # 반전 마스크 및 노이즈 제거
        seg_mask2 = np.where(x_seg_mask < 128, 1, 0) # 128 threshold

        x_lung_seg = x_orig*seg_mask1

        # Gaussian Blur 적용
        x_orig_blur = Image.fromarray(x_orig).convert('L')
        x_orig_blur = x_orig_blur.filter(ImageFilter.GaussianBlur(1))
        x_orig_blur = np.array(x_orig_blur)

        # Lung Segmentation 제외 제거
        x_background = x_orig_blur*seg_mask2 # lung segmentation 제외 비우기
        seg_mask3 = np.where(x_seg_mask > 128, 255, 0).astype(np.uint8) # 타입 CV_8U 오류 방지

        # Background에 Lung Segmentation 붙이기
        x_merge = cv2.copyTo(x_lung_seg, seg_mask3, x_background)
        x_merge = Image.fromarray(x_merge).convert('L')
        
        # Histogram Equalization
        x_merge = ImageOps.equalize(x_merge)
        
        y = self.metadata.loc[idx, 'normal']

        if self.transform:
            x = self.transform(x_merge)

        return x, y

    def __len__(self):
        return self.metadata['normal'].count()


merge_ds = Dataset(metadata, SEG_BASE_PATH, ORIG_BASE_PATH, transform=MERGE_TRANSFORMS)


from torchvision.transforms.functional import to_pil_image

x, y = merge_ds[201]
plt.title(y)
plt.imshow(to_pil_image(x), cmap='gray')
plt.axis('off')
plt.show()


ds_size = len(merge_ds)
train_size = int(ds_size * 0.8)
test_size = ds_size - train_size
merge_train, merge_test = random_split(merge_ds, [train_size, test_size], generator=torch.manual_seed(42))


print(len(merge_train), len(merge_test))


merge_train = copy(merge_train)

TRAIN_TRANSFORM = transforms.Compose([
    transforms.ToTensor(),
    # rotation degree = -10, 10
    # translate -img_width * a < dx < img_width * a
        # -11.2 < dx < 11.2, y도 b로 마찬가지, tuple 형태로
    transforms.RandomAffine(degrees=10, translate=(0.05, 0.05))
])

merge_train.dataset.transform = TRAIN_TRANSFORM


merge_train_dl = DataLoader(merge_train, batch_size=16, shuffle=True)
merge_test_dl = DataLoader(merge_test, batch_size=8, shuffle=True)


class customDenseNet(nn.Module):
    def __init__(self):
        super(customDenseNet, self).__init__()
        self.model = models.densenet121(weights='IMAGENET1K_V1')
        self.model.features.conv0 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)
        self.linear = nn.Linear(1000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.model(x)
        x = self.linear(x)
        x = self.sigmoid(x)

        return x


merge_net = customDenseNet()
merge_net.to(device)


optimizer = torch.optim.Adam(merge_net.parameters(), lr=0.0001)
schedular = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)
weights = (metadata['normal'] == 1).sum() / (metadata['normal'] == 0).sum()
loss_fn = nn.BCEWithLogitsLoss(pos_weight=torch.Tensor([weights])).to(device)


def train(model, data_loader, optimizer, epoch):
    model.train()
    running_loss = 0
    running_acc = 0
    n_data = 0

    for batch_idx, (batch, target) in enumerate(data_loader, start=1):
        batch, target = batch.to(device), target.to(device)

        optimizer.zero_grad()

        output = model(batch)
        
        # print(output.shape, target.shape)
        target_ = target
        target = target.unsqueeze(dim=-1).float()

        loss = loss_fn(output, target)
        running_loss += loss.item()

        predicted = (output >= torch.FloatTensor([0.5]).to(device)).type(torch.float32)
        correct = (predicted == target).sum().item()
        running_acc += correct

        loss.backward()
        optimizer.step()

        n_data += len(batch)
        print(f'\rTrain Epoch: {epoch} [{n_data}/{len(data_loader.dataset)} ({100 * batch_idx / len(data_loader):.2f}%)]  Accuracy: {100*running_acc/n_data:.2f}%  Loss: {running_loss/batch_idx:.4f}', end='') 


def train(model, data_loader, optimizer, epoch):
    model.train()
    running_loss = 0
    running_acc = 0
    n_data = 0

    for batch_idx, (batch, target) in enumerate(data_loader, start=1):
        batch, target = batch.to(device), target.to(device)

        optimizer.zero_grad()

        output = model(batch)
        output_flat = output.view(output.size(0), -1).type(torch.float32)
        target_flat = target.view(target.size(0), -1).type(torch.float32)
        # print(output.shape, target.shape)

        loss = loss_fn(output_flat, target_flat)
        running_loss += loss.item()

        output_flat = (output_flat >= torch.FloatTensor([0.5]).to(device)).type(torch.float32)
        correct = (output_flat == target_flat).sum().item()
        running_acc += correct

        loss.backward()
        optimizer.step()

        n_data += len(batch)
        print(f'\rTrain Epoch: {epoch} [{n_data}/{len(data_loader.dataset)} ({100 * batch_idx / len(data_loader):.2f}%)]  Accuracy: {100*running_acc/n_data:.2f}%  Loss: {running_loss/batch_idx:.4f}', end='')


def test(model, data_loader):
    model.eval()
    test_acc = 0
    test_loss = 0
    n_data = 0
    TP, FP, TN, FN = 0, 0, 0, 0
    with torch.no_grad():
        for batch, target in data_loader:
            batch, target = batch.to(device), target.to(device)

            output = model(batch)
            target = target.unsqueeze(dim=-1).float()

            loss = loss_fn(output, target)
            test_loss += loss.item()

            predicted = (output >= torch.FloatTensor([0.5]).to(device)).type(torch.float32)
            correct = (predicted == target).sum().item()
            test_acc += correct

            TP += ((predicted == target) & (target == 1)).sum().item()
            FP += ((predicted != target) & (target == 0)).sum().item()
            TN += ((predicted == target) & (target == 0)).sum().item()
            FN += ((predicted != target) & (target == 1)).sum().item()
            
            n_data += len(batch)
            print(f'\rTest set: [{100*n_data/len(data_loader.dataset):.2f}%]', end='')
    
    test_acc = 100 * test_acc / len(data_loader.dataset)
    test_loss = test_loss / len(data_loader)
    
    print(f'\rTest set: Accuracy: {test_acc:.2f}%  Loss: {test_loss:.4f}')

    return test_acc, test_loss, TP, FP, TN, FN


def getMetric(TP, FP, TN, FN):
    # base case: divide by zero
    TP = 0.1 if TP == 0 else TP
    FP = 0.1 if FP == 0 else FP
    TN = 0.1 if TN == 0 else TN
    FN = 0.1 if FN == 0 else FN
    
    sensitivity = TP/(TP+FN)
    specificity = TN/(TN+FP)
    precision = TP/(TP+FP)
    recall = TP/(TP+FN)
    f1_score = 2*precision*recall/(precision+recall)
    return sensitivity, specificity, f1_score


accs = []
losses = []
best_acc = 0
best_f1 = 0

best_acc_model = None
best_acc_model_state = None
best_f1_model = None
best_f1_model_state = None


for epoch in range(1, 100+1):
    train(merge_net, merge_train_dl, optimizer, epoch)
    
    print()
    
    acc, loss, tp, fp, tn, fn = test(merge_net, merge_test_dl)
    sensitivity, specificity, f1_score = getMetric(tp, fp, tn, fn)
    print(f'TP: {tp}, FP: {fp}, TN: {tn}, FN: {fn}')
    print(f'Sensitivity: {sensitivity:.4f}, Specificity: {specificity:.4f}, F1-Score: {f1_score:.4f}')

    if acc > best_acc:
        best_acc = acc
        best_acc_model = deepcopy(merge_net)
        best_acc_model_state = deepcopy(merge_net.state_dict())

    if f1_score > best_f1:
        best_f1 = f1_score
        best_f1_model = deepcopy(merge_net)
        best_f1_model_state = deepcopy(merge_net.state_dict())
        
    schedular.step(loss)
    accs.append(acc)
    losses.append(loss)

    print('================================================================')


accs_np = np.array(accs)
losses_np = np.array(losses)
np.save('./merge_mix_acc.npy', accs_np)
np.save('./merge_mix_loss.npy', losses_np)

torch.save(best_acc_model, './merge_best_acc_model.pt')
torch.save(best_acc_model_state, './merge_best_acc_model_state.pt')
torch.save(best_f1_model, './merge_best_f1_model.pt')
torch.save(best_f1_model_state, './merge_best_f1_model_state.pt')
