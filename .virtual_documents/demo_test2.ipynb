


import torch
from torch import nn
from torchvision import transforms
from torchvision.transforms.functional import to_pil_image
import matplotlib.pyplot as plt
from PIL import Image
from torch.utils.data import Dataset
from torch.utils.data import DataLoader
from torch.utils.data import random_split
import sys
import os
import pandas as pd
import numpy as np
import random
from pathlib import Path

os.environ['KMP_DUPLICATE_LIB_OK'] = 'True' # dead kernel for matplotlib


metadata = pd.read_csv('./doby_demo_metadata.csv')
metadata.info()


SEG_BASE_PATH = './chest-x-ray-dataset-with-lung-segmentation-1.0.0/chest-x-ray-dataset-with-lung-segmentation-1.0.0'
ORIG_BASE_PATH = './physionet.org/files/mimic-cxr-jpg/2.0.0'


class Resize(object):
    def __init__(self, size):
        self.size = size

    def __call__(self, x):
        return x.resize((self.size, self.size))

SEG_TRANSFORMS = transforms.Compose([
    transforms.ToTensor()
])

ORIG_TRANSFORMS = transforms.Compose([
    # Resize(224),
    transforms.ToTensor()
])


class Dataset(Dataset):
    def __init__(self, metadata, base_path, transform=None):
        self.metadata = metadata
        self.base_path = Path(base_path)
        self.transform = transform

    def __getitem__(self, idx):
        x_path = self.metadata.loc[idx, 'DicomPath']
        x_path = self.base_path / Path(x_path)
        x = Image.open(x_path).convert('L') # convert를 하지 않으면, ToTensor를 할 때, 3x224x224로 바꾼다.

        y = self.metadata.loc[idx, 'edema_severity']

        if self.transform:
            x = self.transform(x)

        return x, y

    def __len__(self):
        return self.metadata['edema_severity'].count()


seg_ds = Dataset(metadata, SEG_BASE_PATH, transform=SEG_TRANSFORMS)
orig_ds = Dataset(metadata, ORIG_BASE_PATH, transform=ORIG_TRANSFORMS)


ds_size = len(seg_ds)
train_size = int(ds_size * 0.8)
test_size = ds_size - train_size
seg_train, seg_test = random_split(seg_ds, [train_size, test_size], generator=torch.manual_seed(42))
orig_train, orig_test = random_split(orig_ds, [train_size, test_size], generator=torch.manual_seed(42))


seg_train_dl = DataLoader(seg_train, batch_size=1)
seg_test_dl = DataLoader(seg_test, batch_size=1)

orig_train_dl = DataLoader(orig_train, batch_size=1)
orig_test_dl = DataLoader(orig_test, batch_size=1)


from torchvision.transforms.functional import to_pil_image

cnt = 0
for (batch_seg, target_seg), (batch_orig, target_orig) in zip(seg_train_dl, orig_train_dl):
    display.display(plt.gcf())
    display.clear_output(wait=True)
    
    if cnt == 100:
        break
    plt.subplot(1, 2, 1)
    x1 = batch_seg[0]
    plt.imshow(to_pil_image(x1), cmap='gray')
    plt.axis('off')
    plt.title(target_seg.item())

    plt.subplot(1, 2, 2)
    x2 = batch_orig[0]
    plt.imshow(to_pil_image(x2), cmap='gray')
    plt.axis('off')
    plt.title(target_orig.item())
    
    cnt += 1
    time.sleep(0.2)
