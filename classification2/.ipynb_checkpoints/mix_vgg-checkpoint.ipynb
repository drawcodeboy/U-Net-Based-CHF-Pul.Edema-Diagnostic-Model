{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae863a34-6643-44fa-bc3a-bdb4860cd5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from PIL import ImageFilter\n",
    "from PIL import ImageOps\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from copy import copy\n",
    "from copy import deepcopy\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True' # dead kernel for matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b92c0ef-8d09-4b32-b143-5ce85b4f22c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4198 entries, 0 to 4197\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   subject_id      4198 non-null   int64 \n",
      " 1   study_id        4198 non-null   int64 \n",
      " 2   dicom_id        4198 non-null   object\n",
      " 3   DicomPath       4198 non-null   object\n",
      " 4   edema_severity  4198 non-null   int64 \n",
      " 5   normal          4198 non-null   int64 \n",
      " 6   CHF             4198 non-null   bool  \n",
      "dtypes: bool(1), int64(4), object(2)\n",
      "memory usage: 233.7+ KB\n"
     ]
    }
   ],
   "source": [
    "metadata = pd.read_csv('../doby_meta.csv')\n",
    "metadata = metadata[metadata['subject_id'] < 16000000]\n",
    "metadata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31517bce-30b5-4ee2-8a21-59ea06406329",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEG_BASE_PATH = '../chest-x-ray-dataset-with-lung-segmentation-1.0.0/chest-x-ray-dataset-with-lung-segmentation-1.0.0'\n",
    "ORIG_BASE_PATH = '../physionet.org/files/mimic-cxr-jpg/2.0.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90ba4915-2eb3-442f-b501-49d8a99c7a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resize(object):\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "\n",
    "    def __call__(self, x_seg, x_orig):\n",
    "        return x_seg, x_orig.resize((self.size, self.size))\n",
    "\n",
    "class MixImage(object):\n",
    "    def __call__(self, fore, back):\n",
    "        back.paste(fore, (0, 0), fore)\n",
    "        return back\n",
    "\n",
    "TRANSFORMS = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4702f83e-d0bc-40a2-b250-9fe04e6df31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, metadata, seg_base_path, orig_base_path, transform=None):\n",
    "        self.metadata = metadata\n",
    "        self.seg_base_path = Path(seg_base_path)\n",
    "        self.orig_base_path = Path(orig_base_path)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x_path = self.metadata.loc[idx, 'DicomPath']\n",
    "        x_seg_path = self.seg_base_path / Path(x_path)\n",
    "        x_orig_path = self.orig_base_path / Path(x_path)\n",
    "        \n",
    "        x_seg = Image.open(x_seg_path).convert('L').resize((64, 64)) # convert를 하지 않으면, ToTensor를 할 때, 3x224x224로 바꾼다.\n",
    "        x_orig = Image.open(x_orig_path).convert('L').resize(x_seg.size)\n",
    "\n",
    "        '''\n",
    "        plt.subplot(2, 2, 1)\n",
    "        plt.imshow(x_orig, cmap='gray')\n",
    "        plt.axis('off')\n",
    "                    \n",
    "        plt.subplot(2, 2, 2)\n",
    "        plt.imshow(x_seg, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        '''\n",
    "        \n",
    "        x_orig = x_orig.filter(ImageFilter.GaussianBlur(1))\n",
    "\n",
    "        '''\n",
    "        plt.subplot(2, 2, 3)\n",
    "        plt.imshow(x_orig, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        '''\n",
    "\n",
    "        x_mix = Image.blend(x_orig, x_seg, 0.2)\n",
    "\n",
    "        # Histogram Equalization\n",
    "        x_mix = ImageOps.equalize(x_mix)\n",
    "\n",
    "        '''\n",
    "        plt.subplot(2, 2, 4)\n",
    "        plt.imshow(x_mix, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        '''\n",
    "        \n",
    "        y = self.metadata.loc[idx, 'normal']\n",
    "\n",
    "        if self.transform:\n",
    "            x = self.transform(x_mix)\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.metadata['normal'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c523295-c469-4d6e-85ae-9c36d8597333",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset(metadata, SEG_BASE_PATH, ORIG_BASE_PATH, transform=TRANSFORMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0b89ffb-7f2c-4dca-9301-46c3f1a3157c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torchvision.transforms.functional import to_pil_image\n",
    "\n",
    "x, y = ds[201]\n",
    "plt.title(y)\n",
    "plt.imshow(to_pil_image(x), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "718f7151-5393-4321-ba8e-ff36f946bf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_size = len(ds)\n",
    "train_size = int(ds_size * 0.8)\n",
    "test_size = ds_size - train_size\n",
    "train_ds, test_ds = random_split(ds, [train_size, test_size], generator=torch.manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f5c1a73-e48a-43cd-a84a-c76c9aeffb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3358 840\n"
     ]
    }
   ],
   "source": [
    "print(len(train_ds), len(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0c93c66-b81e-43e0-bdaa-185366f7604c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = copy(train_ds)\n",
    "\n",
    "TRAIN_TRANSFORM = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # rotation degree = -10, 10\n",
    "    # translate -img_width * a < dx < img_width * a\n",
    "        # -11.2 < dx < 11.2, y도 b로 마찬가지, tuple 형태로\n",
    "    transforms.RandomAffine(degrees=10, translate=(0.05, 0.05))\n",
    "])\n",
    "\n",
    "train_ds.dataset.transform = TRAIN_TRANSFORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af7c9afb-52fa-45bc-b64a-ca38af213bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "test_dl = DataLoader(test_ds, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27f87a68-0000-4ab3-95aa-8b5fe2b51381",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg16(weights='IMAGENET1K_V1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78c7d83d-9b30-4ecb-aaa6-202694ca8fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6821286c-61e7-41e2-abd0-eeabf120830e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CusVgg16(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CusVgg16, self).__init__()\n",
    "        self.vgg = models.vgg16(weights='IMAGENET1K_V1')\n",
    "        self.vgg.features[0] = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.vgg.classifier[6] = nn.Linear(4096, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.vgg(x)\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "910a2fe8-cf48-4239-84fb-705ce6cd43d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CusVgg16(\n",
       "  (vgg): VGG(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): ReLU(inplace=True)\n",
       "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (13): ReLU(inplace=True)\n",
       "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): ReLU(inplace=True)\n",
       "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (18): ReLU(inplace=True)\n",
       "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (20): ReLU(inplace=True)\n",
       "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (22): ReLU(inplace=True)\n",
       "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (25): ReLU(inplace=True)\n",
       "      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (27): ReLU(inplace=True)\n",
       "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (29): ReLU(inplace=True)\n",
       "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=4096, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = CusVgg16()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7581764a-ac5b-4b51-b7a0-5a642d95b1a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 vgg.features.0.weight\n",
      "1 vgg.features.0.bias\n",
      "2 vgg.features.2.weight\n",
      "3 vgg.features.2.bias\n",
      "4 vgg.features.5.weight\n",
      "5 vgg.features.5.bias\n",
      "6 vgg.features.7.weight\n",
      "7 vgg.features.7.bias\n",
      "8 vgg.features.10.weight\n",
      "9 vgg.features.10.bias\n",
      "10 vgg.features.12.weight\n",
      "11 vgg.features.12.bias\n",
      "12 vgg.features.14.weight\n",
      "13 vgg.features.14.bias\n",
      "14 vgg.features.17.weight\n",
      "15 vgg.features.17.bias\n",
      "16 vgg.features.19.weight\n",
      "17 vgg.features.19.bias\n",
      "18 vgg.features.21.weight\n",
      "19 vgg.features.21.bias\n",
      "20 vgg.features.24.weight\n",
      "21 vgg.features.24.bias\n",
      "22 vgg.features.26.weight\n",
      "23 vgg.features.26.bias\n",
      "24 vgg.features.28.weight\n",
      "25 vgg.features.28.bias\n",
      "26 vgg.classifier.0.weight\n",
      "27 vgg.classifier.0.bias\n",
      "28 vgg.classifier.3.weight\n",
      "29 vgg.classifier.3.bias\n",
      "30 vgg.classifier.6.weight\n",
      "31 vgg.classifier.6.bias\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for name, param in model.named_parameters():\n",
    "    print(i, name)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cab9f0a5-40f9-4cc7-bc89-375154d37487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requires_grad = True\n",
      "requires_grad = True\n",
      "requires_grad = True\n",
      "requires_grad = True\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for name, param in model.named_parameters():\n",
    "    if i == 0 or i == 1 or i == 30 or i == 31:\n",
    "        print('requires_grad = True')\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ff2d170-955f-4e64-be85-9feafb26dfb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(model.vgg.features[0].weight.requires_grad)\n",
    "print(model.vgg.features[0].bias.requires_grad)\n",
    "print(model.vgg.classifier[6].weight.requires_grad)\n",
    "print(model.vgg.classifier[6].bias.requires_grad)\n",
    "print(model.vgg.classifier[3].bias.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84df2ccc-0b1b-4f23-b5d5-a8ad4326e507",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "schedular = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "weights = (metadata['normal'] == 1).sum() / (metadata['normal'] == 0).sum()\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=torch.Tensor([weights])).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10ad465c-5bf8-41b4-a456-f6bd5a2fe1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    running_acc = 0\n",
    "    n_data = 0\n",
    "\n",
    "    for batch_idx, (batch, target) in enumerate(data_loader, start=1):\n",
    "        batch, target = batch.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(batch)\n",
    "        # print(output.shape, target.shape)\n",
    "        target_ = target\n",
    "        target = target.unsqueeze(dim=-1).float()\n",
    "\n",
    "        loss = loss_fn(output, target)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        predicted = (output >= torch.FloatTensor([0.5]).to(device)).type(torch.float32)\n",
    "        correct = (predicted == target).sum().item()\n",
    "        running_acc += correct\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        n_data += len(batch)\n",
    "        print(f'\\rTrain Epoch: {epoch} [{n_data}/{len(data_loader.dataset)} ({100 * batch_idx / len(data_loader):.2f}%)]  Accuracy: {100*running_acc/n_data:.2f}%  Loss: {running_loss/batch_idx:.4f}', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3808f73f-add2-431b-9eca-75f00acdf75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, data_loader):\n",
    "    model.eval()\n",
    "    test_acc = 0\n",
    "    test_loss = 0\n",
    "    n_data = 0\n",
    "    TP, FP, TN, FN = 0, 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch, target in data_loader:\n",
    "            batch, target = batch.to(device), target.to(device)\n",
    "\n",
    "            output = model(batch)\n",
    "            target = target.unsqueeze(dim=-1).float()\n",
    "\n",
    "            loss = loss_fn(output, target)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            predicted = (output >= torch.FloatTensor([0.5]).to(device)).type(torch.float32)\n",
    "            correct = (predicted == target).sum().item()\n",
    "            test_acc += correct\n",
    "\n",
    "            TP += ((predicted == target) & (target == 1)).sum().item()\n",
    "            FP += ((predicted != target) & (target == 0)).sum().item()\n",
    "            TN += ((predicted == target) & (target == 0)).sum().item()\n",
    "            FN += ((predicted != target) & (target == 1)).sum().item()\n",
    "            \n",
    "            n_data += len(batch)\n",
    "            print(f'\\rTest set: [{100*n_data/len(data_loader.dataset):.2f}%]', end='')\n",
    "    \n",
    "    test_acc = 100 * test_acc / len(data_loader.dataset)\n",
    "    test_loss = test_loss / len(data_loader)\n",
    "    \n",
    "    print(f'\\rTest set: Accuracy: {test_acc:.2f}%  Loss: {test_loss:.4f}')\n",
    "\n",
    "    return test_acc, test_loss, TP, FP, TN, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "962909b8-5b13-4534-a91c-36286985edc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMetric(TP, FP, TN, FN):\n",
    "    # base case: divide by zero\n",
    "    TP = 0.1 if TP == 0 else TP\n",
    "    FP = 0.1 if FP == 0 else FP\n",
    "    TN = 0.1 if TN == 0 else TN\n",
    "    FN = 0.1 if FN == 0 else FN\n",
    "    \n",
    "    sensitivity = TP/(TP+FN)\n",
    "    specificity = TN/(TN+FP)\n",
    "    precision = TP/(TP+FP)\n",
    "    recall = TP/(TP+FN)\n",
    "    f1_score = 2*precision*recall/(precision+recall)\n",
    "    return sensitivity, specificity, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "406f5f21-9ae0-4949-a020-02ec60aba9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = []\n",
    "losses = []\n",
    "best_acc = 0\n",
    "best_f1 = 0\n",
    "\n",
    "best_acc_model = None\n",
    "best_acc_model_state = None\n",
    "best_f1_model = None\n",
    "best_f1_model_state = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b133f06c-9641-4843-a51c-c653ac6e4fc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [3358/3358 (100.00%)]  Accuracy: 58.34%  Loss: 0.7852\n",
      "Test set: Accuracy: 59.88%  Loss: 0.7710\n",
      "TP: 369, FP: 205, TN: 134, FN: 132\n",
      "Sensitivity: 0.7365, Specificity: 0.3953, F1-Score: 0.6865\n",
      "================================================================\n",
      "Train Epoch: 2 [3358/3358 (100.00%)]  Accuracy: 61.08%  Loss: 0.7669\n",
      "Test set: Accuracy: 61.79%  Loss: 0.7656\n",
      "TP: 419, FP: 239, TN: 100, FN: 82\n",
      "Sensitivity: 0.8363, Specificity: 0.2950, F1-Score: 0.7230\n",
      "================================================================\n",
      "Train Epoch: 3 [3358/3358 (100.00%)]  Accuracy: 61.55%  Loss: 0.7650\n",
      "Test set: Accuracy: 53.81%  Loss: 0.7820\n",
      "TP: 192, FP: 79, TN: 260, FN: 309\n",
      "Sensitivity: 0.3832, Specificity: 0.7670, F1-Score: 0.4974\n",
      "================================================================\n",
      "Train Epoch: 4 [3358/3358 (100.00%)]  Accuracy: 61.97%  Loss: 0.7626\n",
      "Test set: Accuracy: 62.02%  Loss: 0.7572\n",
      "TP: 366, FP: 184, TN: 155, FN: 135\n",
      "Sensitivity: 0.7305, Specificity: 0.4572, F1-Score: 0.6965\n",
      "================================================================\n",
      "Train Epoch: 5 [3358/3358 (100.00%)]  Accuracy: 62.60%  Loss: 0.7595\n",
      "Test set: Accuracy: 63.57%  Loss: 0.7529\n",
      "TP: 371, FP: 176, TN: 163, FN: 130\n",
      "Sensitivity: 0.7405, Specificity: 0.4808, F1-Score: 0.7080\n",
      "================================================================\n",
      "Train Epoch: 6 [3358/3358 (100.00%)]  Accuracy: 61.85%  Loss: 0.7611\n",
      "Test set: Accuracy: 61.79%  Loss: 0.7624\n",
      "TP: 349, FP: 169, TN: 170, FN: 152\n",
      "Sensitivity: 0.6966, Specificity: 0.5015, F1-Score: 0.6850\n",
      "================================================================\n",
      "Train Epoch: 7 [3358/3358 (100.00%)]  Accuracy: 61.97%  Loss: 0.7623\n",
      "Test set: Accuracy: 61.19%  Loss: 0.7666\n",
      "TP: 417, FP: 242, TN: 97, FN: 84\n",
      "Sensitivity: 0.8323, Specificity: 0.2861, F1-Score: 0.7190\n",
      "================================================================\n",
      "Train Epoch: 8 [3358/3358 (100.00%)]  Accuracy: 62.09%  Loss: 0.7612\n",
      "Test set: Accuracy: 59.76%  Loss: 0.7621\n",
      "TP: 334, FP: 171, TN: 168, FN: 167\n",
      "Sensitivity: 0.6667, Specificity: 0.4956, F1-Score: 0.6640\n",
      "================================================================\n",
      "Train Epoch: 9 [3358/3358 (100.00%)]  Accuracy: 62.27%  Loss: 0.7582\n",
      "Test set: Accuracy: 57.98%  Loss: 0.7717\n",
      "TP: 231, FP: 83, TN: 256, FN: 270\n",
      "Sensitivity: 0.4611, Specificity: 0.7552, F1-Score: 0.5669\n",
      "================================================================\n",
      "Train Epoch: 10 [3358/3358 (100.00%)]  Accuracy: 62.03%  Loss: 0.7638\n",
      "Test set: Accuracy: 62.62%  Loss: 0.7618\n",
      "TP: 385, FP: 198, TN: 141, FN: 116\n",
      "Sensitivity: 0.7685, Specificity: 0.4159, F1-Score: 0.7103\n",
      "================================================================\n",
      "Train Epoch: 11 [3358/3358 (100.00%)]  Accuracy: 61.82%  Loss: 0.7623\n",
      "Test set: Accuracy: 61.31%  Loss: 0.7609\n",
      "TP: 324, FP: 148, TN: 191, FN: 177\n",
      "Sensitivity: 0.6467, Specificity: 0.5634, F1-Score: 0.6660\n",
      "Epoch 00011: reducing learning rate of group 0 to 1.0000e-04.\n",
      "================================================================\n",
      "Train Epoch: 12 [3358/3358 (100.00%)]  Accuracy: 63.40%  Loss: 0.7530\n",
      "Test set: Accuracy: 60.36%  Loss: 0.7596\n",
      "TP: 299, FP: 131, TN: 208, FN: 202\n",
      "Sensitivity: 0.5968, Specificity: 0.6136, F1-Score: 0.6423\n",
      "================================================================\n",
      "Train Epoch: 13 [3358/3358 (100.00%)]  Accuracy: 63.49%  Loss: 0.7544\n",
      "Test set: Accuracy: 60.95%  Loss: 0.7595\n",
      "TP: 326, FP: 153, TN: 186, FN: 175\n",
      "Sensitivity: 0.6507, Specificity: 0.5487, F1-Score: 0.6653\n",
      "================================================================\n",
      "Train Epoch: 14 [3358/3358 (100.00%)]  Accuracy: 63.88%  Loss: 0.7531\n",
      "Test set: Accuracy: 61.90%  Loss: 0.7554\n",
      "TP: 305, FP: 124, TN: 215, FN: 196\n",
      "Sensitivity: 0.6088, Specificity: 0.6342, F1-Score: 0.6559\n",
      "================================================================\n",
      "Train Epoch: 15 [3358/3358 (100.00%)]  Accuracy: 63.19%  Loss: 0.7562\n",
      "Test set: Accuracy: 62.14%  Loss: 0.7547\n",
      "TP: 326, FP: 143, TN: 196, FN: 175\n",
      "Sensitivity: 0.6507, Specificity: 0.5782, F1-Score: 0.6722\n",
      "================================================================\n",
      "Train Epoch: 16 [3358/3358 (100.00%)]  Accuracy: 63.46%  Loss: 0.7540\n",
      "Test set: Accuracy: 60.71%  Loss: 0.7589\n",
      "TP: 321, FP: 150, TN: 189, FN: 180\n",
      "Sensitivity: 0.6407, Specificity: 0.5575, F1-Score: 0.6605\n",
      "================================================================\n",
      "Train Epoch: 17 [3358/3358 (100.00%)]  Accuracy: 63.61%  Loss: 0.7535\n",
      "Test set: Accuracy: 61.31%  Loss: 0.7592\n",
      "TP: 309, FP: 133, TN: 206, FN: 192\n",
      "Sensitivity: 0.6168, Specificity: 0.6077, F1-Score: 0.6554\n",
      "Epoch 00017: reducing learning rate of group 0 to 1.0000e-05.\n",
      "================================================================\n",
      "Train Epoch: 18 [3358/3358 (100.00%)]  Accuracy: 64.00%  Loss: 0.7519\n",
      "Test set: Accuracy: 62.14%  Loss: 0.7564\n",
      "TP: 327, FP: 144, TN: 195, FN: 174\n",
      "Sensitivity: 0.6527, Specificity: 0.5752, F1-Score: 0.6728\n",
      "================================================================\n",
      "Train Epoch: 19 [3358/3358 (100.00%)]  Accuracy: 65.04%  Loss: 0.7519\n",
      "Test set: Accuracy: 62.50%  Loss: 0.7545\n",
      "TP: 329, FP: 143, TN: 196, FN: 172\n",
      "Sensitivity: 0.6567, Specificity: 0.5782, F1-Score: 0.6763\n",
      "================================================================\n",
      "Train Epoch: 20 [3358/3358 (100.00%)]  Accuracy: 64.68%  Loss: 0.7492\n",
      "Test set: Accuracy: 60.48%  Loss: 0.7604\n",
      "TP: 318, FP: 149, TN: 190, FN: 183\n",
      "Sensitivity: 0.6347, Specificity: 0.5605, F1-Score: 0.6570\n",
      "================================================================\n",
      "Train Epoch: 21 [3358/3358 (100.00%)]  Accuracy: 63.79%  Loss: 0.7519\n",
      "Test set: Accuracy: 60.83%  Loss: 0.7588\n",
      "TP: 322, FP: 150, TN: 189, FN: 179\n",
      "Sensitivity: 0.6427, Specificity: 0.5575, F1-Score: 0.6619\n",
      "================================================================\n",
      "Train Epoch: 22 [3358/3358 (100.00%)]  Accuracy: 64.68%  Loss: 0.7517\n",
      "Test set: Accuracy: 61.31%  Loss: 0.7608\n",
      "TP: 325, FP: 149, TN: 190, FN: 176\n",
      "Sensitivity: 0.6487, Specificity: 0.5605, F1-Score: 0.6667\n",
      "================================================================\n",
      "Train Epoch: 23 [3358/3358 (100.00%)]  Accuracy: 63.94%  Loss: 0.7529\n",
      "Test set: Accuracy: 60.95%  Loss: 0.7614\n",
      "TP: 326, FP: 153, TN: 186, FN: 175\n",
      "Sensitivity: 0.6507, Specificity: 0.5487, F1-Score: 0.6653\n",
      "Epoch 00023: reducing learning rate of group 0 to 1.0000e-06.\n",
      "================================================================\n",
      "Train Epoch: 24 [3358/3358 (100.00%)]  Accuracy: 64.23%  Loss: 0.7498\n",
      "Test set: Accuracy: 59.64%  Loss: 0.7593\n",
      "TP: 318, FP: 156, TN: 183, FN: 183\n",
      "Sensitivity: 0.6347, Specificity: 0.5398, F1-Score: 0.6523\n",
      "================================================================\n",
      "Train Epoch: 25 [3358/3358 (100.00%)]  Accuracy: 63.55%  Loss: 0.7527\n",
      "Test set: Accuracy: 62.02%  Loss: 0.7567\n",
      "TP: 327, FP: 145, TN: 194, FN: 174\n",
      "Sensitivity: 0.6527, Specificity: 0.5723, F1-Score: 0.6721\n",
      "================================================================\n",
      "Train Epoch: 26 [3358/3358 (100.00%)]  Accuracy: 63.73%  Loss: 0.7531\n",
      "Test set: Accuracy: 61.43%  Loss: 0.7576\n",
      "TP: 322, FP: 145, TN: 194, FN: 179\n",
      "Sensitivity: 0.6427, Specificity: 0.5723, F1-Score: 0.6653\n",
      "================================================================\n",
      "Train Epoch: 27 [3358/3358 (100.00%)]  Accuracy: 63.01%  Loss: 0.7560\n",
      "Test set: Accuracy: 61.67%  Loss: 0.7572\n",
      "TP: 331, FP: 152, TN: 187, FN: 170\n",
      "Sensitivity: 0.6607, Specificity: 0.5516, F1-Score: 0.6728\n",
      "================================================================\n",
      "Train Epoch: 28 [3358/3358 (100.00%)]  Accuracy: 63.88%  Loss: 0.7535\n",
      "Test set: Accuracy: 62.86%  Loss: 0.7539\n",
      "TP: 325, FP: 136, TN: 203, FN: 176\n",
      "Sensitivity: 0.6487, Specificity: 0.5988, F1-Score: 0.6757\n",
      "================================================================\n",
      "Train Epoch: 29 [3358/3358 (100.00%)]  Accuracy: 63.22%  Loss: 0.7539\n",
      "Test set: Accuracy: 62.86%  Loss: 0.7563\n",
      "TP: 331, FP: 142, TN: 197, FN: 170\n",
      "Sensitivity: 0.6607, Specificity: 0.5811, F1-Score: 0.6797\n",
      "Epoch 00029: reducing learning rate of group 0 to 1.0000e-07.\n",
      "================================================================\n",
      "Train Epoch: 30 [3358/3358 (100.00%)]  Accuracy: 64.18%  Loss: 0.7530\n",
      "Test set: Accuracy: 61.90%  Loss: 0.7545\n",
      "TP: 330, FP: 149, TN: 190, FN: 171\n",
      "Sensitivity: 0.6587, Specificity: 0.5605, F1-Score: 0.6735\n",
      "================================================================\n",
      "Train Epoch: 31 [96/3358 (2.86%)]  Accuracy: 62.50%  Loss: 0.7365"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m50\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     train(model, train_dl, optimizer, epoch)\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m()\n\u001b[0;32m      6\u001b[0m     acc, loss, tp, fp, tn, fn \u001b[38;5;241m=\u001b[39m test(model, test_dl)\n",
      "Cell \u001b[1;32mIn[20], line 18\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, data_loader, optimizer, epoch)\u001b[0m\n\u001b[0;32m     15\u001b[0m target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39munsqueeze(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m     17\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(output, target)\n\u001b[1;32m---> 18\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     20\u001b[0m predicted \u001b[38;5;241m=\u001b[39m (output \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor([\u001b[38;5;241m0.5\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device))\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     21\u001b[0m correct \u001b[38;5;241m=\u001b[39m (predicted \u001b[38;5;241m==\u001b[39m target)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 50+1):\n",
    "    train(model, train_dl, optimizer, epoch)\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    acc, loss, tp, fp, tn, fn = test(model, test_dl)\n",
    "    sensitivity, specificity, f1_score = getMetric(tp, fp, tn, fn)\n",
    "    print(f'TP: {tp}, FP: {fp}, TN: {tn}, FN: {fn}')\n",
    "    print(f'Sensitivity: {sensitivity:.4f}, Specificity: {specificity:.4f}, F1-Score: {f1_score:.4f}')\n",
    "\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_acc_model = deepcopy(model)\n",
    "        best_acc_model_state = deepcopy(model.state_dict())\n",
    "\n",
    "    if f1_score > best_f1:\n",
    "        best_f1 = f1_score\n",
    "        best_f1_model = deepcopy(model)\n",
    "        best_f1_model_state = deepcopy(model.state_dict())\n",
    "        \n",
    "    schedular.step(loss)\n",
    "    accs.append(acc)\n",
    "    losses.append(loss)\n",
    "\n",
    "    print('================================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0001987a-1166-4936-af98-0ce84f96c334",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_np = np.array(accs)\n",
    "losses_np = np.array(losses)\n",
    "np.save('./parameters/mix_acc.npy', accs_np)\n",
    "np.save('./parameters/mix_loss.npy', losses_np)\n",
    "\n",
    "torch.save(best_acc_model, './parameters/mix_best_acc_model.pt')\n",
    "torch.save(best_acc_model_state, './parameters/mix_best_acc_model_state.pt')\n",
    "torch.save(best_f1_model, './parameters/mix_best_f1_model.pt')\n",
    "torch.save(best_f1_model_state, './parameters/mix_best_f1_model_state.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
