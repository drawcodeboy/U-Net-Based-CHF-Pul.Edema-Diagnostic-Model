{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5f5fa7a-9d16-4a0a-856a-1e53edfccd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from PIL import ImageFilter\n",
    "from PIL import ImageOps\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from copy import copy\n",
    "from copy import deepcopy\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True' # dead kernel for matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75cd9a73-9ac3-4019-ac0b-d2ec3933ab4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "061a30c3-4dc7-4a57-94fc-ca622f3dc81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7064 entries, 0 to 7063\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   subject_id      7064 non-null   int64 \n",
      " 1   study_id        7064 non-null   int64 \n",
      " 2   dicom_id        7064 non-null   object\n",
      " 3   DicomPath       7064 non-null   object\n",
      " 4   edema_severity  7064 non-null   int64 \n",
      " 5   normal          7064 non-null   int64 \n",
      " 6   CHF             7064 non-null   bool  \n",
      "dtypes: bool(1), int64(4), object(2)\n",
      "memory usage: 338.2+ KB\n"
     ]
    }
   ],
   "source": [
    "metadata = pd.read_csv('../doby_meta.csv')\n",
    "metadata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d624f712-7c99-4307-a69e-ec6fed7f8ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4198 entries, 0 to 4197\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   subject_id      4198 non-null   int64 \n",
      " 1   study_id        4198 non-null   int64 \n",
      " 2   dicom_id        4198 non-null   object\n",
      " 3   DicomPath       4198 non-null   object\n",
      " 4   edema_severity  4198 non-null   int64 \n",
      " 5   normal          4198 non-null   int64 \n",
      " 6   CHF             4198 non-null   bool  \n",
      "dtypes: bool(1), int64(4), object(2)\n",
      "memory usage: 233.7+ KB\n"
     ]
    }
   ],
   "source": [
    "metadata = metadata[metadata['subject_id'] < 16000000]\n",
    "metadata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92b82733-7fb6-4568-92a7-6435c77b66d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEG_BASE_PATH = '../chest-x-ray-dataset-with-lung-segmentation-1.0.0/chest-x-ray-dataset-with-lung-segmentation-1.0.0'\n",
    "ORIG_BASE_PATH = '../physionet.org/files/mimic-cxr-jpg/2.0.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4786dc4d-739e-4a39-b3a3-3637ca8cc7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resize(object):\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "\n",
    "    def __call__(self, x_seg, x_orig):\n",
    "        return x_seg, x_orig.resize((self.size, self.size))\n",
    "\n",
    "class MixImage(object):\n",
    "    def __call__(self, fore, back):\n",
    "        back.paste(fore, (0, 0), fore)\n",
    "        return back\n",
    "\n",
    "TRANSFORMS = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d97f46e9-ab63-4b8a-9f96-00a78d30ba94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, metadata, orig_base_path, transform=None):\n",
    "        self.metadata = metadata\n",
    "        self.orig_base_path = Path(orig_base_path)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x_path = self.metadata.loc[idx, 'DicomPath']\n",
    "        x_orig_path = self.orig_base_path / Path(x_path)\n",
    "        \n",
    "        x_orig = Image.open(x_orig_path).convert('L').resize((64, 64))\n",
    "\n",
    "        # x_orig = x_orig.filter(ImageFilter.GaussianBlur(2))\n",
    "\n",
    "        x_orig = ImageOps.equalize(x_orig)\n",
    "        \n",
    "        y = self.metadata.loc[idx, 'normal']\n",
    "\n",
    "        if self.transform:\n",
    "            x = self.transform(x_orig)\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.metadata['normal'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8672ef33-1416-45cb-8579-9c9497ffdcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset(metadata, ORIG_BASE_PATH, transform=TRANSFORMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b49c3500-86ba-482a-b16a-c0037f9a125f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torchvision.transforms.functional import to_pil_image\n",
    "\n",
    "x, y = ds[201]\n",
    "plt.title(y)\n",
    "plt.imshow(to_pil_image(x), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dccc0d0f-82cd-4ae8-8f59-64b51ca84d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_size = len(ds)\n",
    "train_size = int(ds_size * 0.8)\n",
    "test_size = ds_size - train_size\n",
    "train_ds, test_ds = random_split(ds, [train_size, test_size], generator=torch.manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20021866-e510-453f-a554-9c02e122add3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3358 840\n"
     ]
    }
   ],
   "source": [
    "print(len(train_ds), len(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13db3218-9ad0-40a4-9887-03263d78c6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = copy(train_ds)\n",
    "\n",
    "TRAIN_TRANSFORM = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # rotation degree = -10, 10\n",
    "    # translate -img_width * a < dx < img_width * a\n",
    "        # -11.2 < dx < 11.2, y도 b로 마찬가지, tuple 형태로\n",
    "    transforms.RandomAffine(degrees=10, translate=(0.05, 0.05))\n",
    "])\n",
    "\n",
    "train_ds.dataset.transform = TRAIN_TRANSFORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1d99fd2-6239-421e-ac84-875237195df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "test_dl = DataLoader(test_ds, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e72bdca3-2427-47a9-a4ef-76475ca754d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CusVgg16(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CusVgg16, self).__init__()\n",
    "        self.vgg = models.vgg16(weights='IMAGENET1K_V1')\n",
    "        self.vgg.features[0] = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.vgg.classifier[6] = nn.Linear(4096, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.vgg(x)\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91cd15e7-2057-4d6f-ba80-672ac2e7a7ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CusVgg16(\n",
       "  (vgg): VGG(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): ReLU(inplace=True)\n",
       "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (13): ReLU(inplace=True)\n",
       "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): ReLU(inplace=True)\n",
       "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (18): ReLU(inplace=True)\n",
       "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (20): ReLU(inplace=True)\n",
       "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (22): ReLU(inplace=True)\n",
       "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (25): ReLU(inplace=True)\n",
       "      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (27): ReLU(inplace=True)\n",
       "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (29): ReLU(inplace=True)\n",
       "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=4096, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = CusVgg16()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1993a2e1-786f-44e2-926c-ec1d313a4c55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 vgg.features.0.weight\n",
      "1 vgg.features.0.bias\n",
      "2 vgg.features.2.weight\n",
      "3 vgg.features.2.bias\n",
      "4 vgg.features.5.weight\n",
      "5 vgg.features.5.bias\n",
      "6 vgg.features.7.weight\n",
      "7 vgg.features.7.bias\n",
      "8 vgg.features.10.weight\n",
      "9 vgg.features.10.bias\n",
      "10 vgg.features.12.weight\n",
      "11 vgg.features.12.bias\n",
      "12 vgg.features.14.weight\n",
      "13 vgg.features.14.bias\n",
      "14 vgg.features.17.weight\n",
      "15 vgg.features.17.bias\n",
      "16 vgg.features.19.weight\n",
      "17 vgg.features.19.bias\n",
      "18 vgg.features.21.weight\n",
      "19 vgg.features.21.bias\n",
      "20 vgg.features.24.weight\n",
      "21 vgg.features.24.bias\n",
      "22 vgg.features.26.weight\n",
      "23 vgg.features.26.bias\n",
      "24 vgg.features.28.weight\n",
      "25 vgg.features.28.bias\n",
      "26 vgg.classifier.0.weight\n",
      "27 vgg.classifier.0.bias\n",
      "28 vgg.classifier.3.weight\n",
      "29 vgg.classifier.3.bias\n",
      "30 vgg.classifier.6.weight\n",
      "31 vgg.classifier.6.bias\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for name, param in model.named_parameters():\n",
    "    print(i, name)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1cea3c0-d278-47d6-92ec-fcb3921110bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requires_grad = True\n",
      "requires_grad = True\n",
      "requires_grad = True\n",
      "requires_grad = True\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for name, param in model.named_parameters():\n",
    "    if i == 0 or i == 1 or i == 30 or i == 31:\n",
    "        print('requires_grad = True')\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae412031-e271-4592-801e-6cfc43d9d848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(model.vgg.features[0].weight.requires_grad)\n",
    "print(model.vgg.features[0].bias.requires_grad)\n",
    "print(model.vgg.classifier[6].weight.requires_grad)\n",
    "print(model.vgg.classifier[6].bias.requires_grad)\n",
    "print(model.vgg.classifier[3].bias.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c53211a-19ab-4a4c-8dbd-cdc661104c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "schedular = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "weights = (metadata['normal'] == 0).sum() / (metadata['normal'] == 1).sum()\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=torch.Tensor([weights])).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "120cb532-d591-43d2-8eeb-14dcbd8a5e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    running_acc = 0\n",
    "    n_data = 0\n",
    "\n",
    "    for batch_idx, (batch, target) in enumerate(data_loader, start=1):\n",
    "        batch, target = batch.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(batch)\n",
    "        # print(output.shape, target.shape)\n",
    "        target_ = target\n",
    "        target = target.unsqueeze(dim=-1).float()\n",
    "\n",
    "        loss = loss_fn(output, target)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        predicted = (output >= torch.FloatTensor([0.5]).to(device)).type(torch.float32)\n",
    "        correct = (predicted == target).sum().item()\n",
    "        running_acc += correct\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        n_data += len(batch)\n",
    "        print(f'\\rTrain Epoch: {epoch} [{n_data}/{len(data_loader.dataset)} ({100 * batch_idx / len(data_loader):.2f}%)]  Accuracy: {100*running_acc/n_data:.2f}%  Loss: {running_loss/batch_idx:.4f}', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee23cd11-d862-4790-b640-a0703679befc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, data_loader):\n",
    "    model.eval()\n",
    "    test_acc = 0\n",
    "    test_loss = 0\n",
    "    n_data = 0\n",
    "    TP, FP, TN, FN = 0, 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch, target in data_loader:\n",
    "            batch, target = batch.to(device), target.to(device)\n",
    "\n",
    "            output = model(batch)\n",
    "            target = target.unsqueeze(dim=-1).float()\n",
    "\n",
    "            loss = loss_fn(output, target)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            predicted = (output >= torch.FloatTensor([0.5]).to(device)).type(torch.float32)\n",
    "            correct = (predicted == target).sum().item()\n",
    "            test_acc += correct\n",
    "\n",
    "            TP += ((predicted == target) & (target == 1)).sum().item()\n",
    "            FP += ((predicted != target) & (target == 0)).sum().item()\n",
    "            TN += ((predicted == target) & (target == 0)).sum().item()\n",
    "            FN += ((predicted != target) & (target == 1)).sum().item()\n",
    "            \n",
    "            n_data += len(batch)\n",
    "            print(f'\\rTest set: [{100*n_data/len(data_loader.dataset):.2f}%]', end='')\n",
    "    \n",
    "    test_acc = 100 * test_acc / len(data_loader.dataset)\n",
    "    test_loss = test_loss / len(data_loader)\n",
    "    \n",
    "    print(f'\\rTest set: Accuracy: {test_acc:.2f}%  Loss: {test_loss:.4f}')\n",
    "\n",
    "    return test_acc, test_loss, TP, FP, TN, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8815f35-6314-4a99-b1cc-d2901e071ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMetric(TP, FP, TN, FN):\n",
    "    # base case: divide by zero\n",
    "    TP = 0.1 if TP == 0 else TP\n",
    "    FP = 0.1 if FP == 0 else FP\n",
    "    TN = 0.1 if TN == 0 else TN\n",
    "    FN = 0.1 if FN == 0 else FN\n",
    "    \n",
    "    sensitivity = TP/(TP+FN)\n",
    "    specificity = TN/(TN+FP)\n",
    "    precision = TP/(TP+FP)\n",
    "    recall = TP/(TP+FN)\n",
    "    f1_score = 2*precision*recall/(precision+recall)\n",
    "    return sensitivity, specificity, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "563014d3-2b4e-4b3c-86a3-4102196b1735",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = []\n",
    "losses = []\n",
    "best_acc = 0\n",
    "best_f1 = 0\n",
    "\n",
    "best_acc_model = None\n",
    "best_acc_model_state = None\n",
    "best_f1_model = None\n",
    "best_f1_model_state = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d47b8dc2-72d1-41a9-9d01-6083a753bbe4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [3358/3358 (100.00%)]  Accuracy: 59.74%  Loss: 0.7799\n",
      "Test set: Accuracy: 60.24%  Loss: 0.7676\n",
      "TP: 347, FP: 180, TN: 159, FN: 154\n",
      "Sensitivity: 0.6926, Specificity: 0.4690, F1-Score: 0.6751\n",
      "================================================================\n",
      "Train Epoch: 2 [3358/3358 (100.00%)]  Accuracy: 61.35%  Loss: 0.7698\n",
      "Test set: Accuracy: 60.12%  Loss: 0.7703\n",
      "TP: 346, FP: 180, TN: 159, FN: 155\n",
      "Sensitivity: 0.6906, Specificity: 0.4690, F1-Score: 0.6738\n",
      "================================================================\n",
      "Train Epoch: 3 [3358/3358 (100.00%)]  Accuracy: 61.58%  Loss: 0.7633\n",
      "Test set: Accuracy: 57.50%  Loss: 0.7776\n",
      "TP: 262, FP: 118, TN: 221, FN: 239\n",
      "Sensitivity: 0.5230, Specificity: 0.6519, F1-Score: 0.5948\n",
      "================================================================\n",
      "Train Epoch: 4 [3358/3358 (100.00%)]  Accuracy: 60.78%  Loss: 0.7698\n",
      "Test set: Accuracy: 61.79%  Loss: 0.7679\n",
      "TP: 425, FP: 245, TN: 94, FN: 76\n",
      "Sensitivity: 0.8483, Specificity: 0.2773, F1-Score: 0.7259\n",
      "================================================================\n",
      "Train Epoch: 5 [3358/3358 (100.00%)]  Accuracy: 61.35%  Loss: 0.7662\n",
      "Test set: Accuracy: 59.64%  Loss: 0.7688\n",
      "TP: 337, FP: 175, TN: 164, FN: 164\n",
      "Sensitivity: 0.6727, Specificity: 0.4838, F1-Score: 0.6654\n",
      "================================================================\n",
      "Train Epoch: 6 [3358/3358 (100.00%)]  Accuracy: 61.82%  Loss: 0.7644\n",
      "Test set: Accuracy: 62.38%  Loss: 0.7584\n",
      "TP: 373, FP: 188, TN: 151, FN: 128\n",
      "Sensitivity: 0.7445, Specificity: 0.4454, F1-Score: 0.7024\n",
      "================================================================\n",
      "Train Epoch: 7 [3358/3358 (100.00%)]  Accuracy: 62.33%  Loss: 0.7615\n",
      "Test set: Accuracy: 59.52%  Loss: 0.7691\n",
      "TP: 310, FP: 149, TN: 190, FN: 191\n",
      "Sensitivity: 0.6188, Specificity: 0.5605, F1-Score: 0.6458\n",
      "================================================================\n",
      "Train Epoch: 8 [3358/3358 (100.00%)]  Accuracy: 62.66%  Loss: 0.7620\n",
      "Test set: Accuracy: 61.07%  Loss: 0.7649\n",
      "TP: 357, FP: 183, TN: 156, FN: 144\n",
      "Sensitivity: 0.7126, Specificity: 0.4602, F1-Score: 0.6859\n",
      "================================================================\n",
      "Train Epoch: 9 [3358/3358 (100.00%)]  Accuracy: 61.67%  Loss: 0.7641\n",
      "Test set: Accuracy: 61.67%  Loss: 0.7614\n",
      "TP: 368, FP: 189, TN: 150, FN: 133\n",
      "Sensitivity: 0.7345, Specificity: 0.4425, F1-Score: 0.6957\n",
      "================================================================\n",
      "Train Epoch: 10 [3358/3358 (100.00%)]  Accuracy: 61.97%  Loss: 0.7636\n",
      "Test set: Accuracy: 61.43%  Loss: 0.7704\n",
      "TP: 429, FP: 252, TN: 87, FN: 72\n",
      "Sensitivity: 0.8563, Specificity: 0.2566, F1-Score: 0.7259\n",
      "================================================================\n",
      "Train Epoch: 11 [3358/3358 (100.00%)]  Accuracy: 63.16%  Loss: 0.7566\n",
      "Test set: Accuracy: 59.64%  Loss: 0.7682\n",
      "TP: 258, FP: 96, TN: 243, FN: 243\n",
      "Sensitivity: 0.5150, Specificity: 0.7168, F1-Score: 0.6035\n",
      "================================================================\n",
      "Train Epoch: 12 [3358/3358 (100.00%)]  Accuracy: 63.67%  Loss: 0.7554\n",
      "Test set: Accuracy: 60.12%  Loss: 0.7668\n",
      "TP: 371, FP: 205, TN: 134, FN: 130\n",
      "Sensitivity: 0.7405, Specificity: 0.3953, F1-Score: 0.6890\n",
      "Epoch 00012: reducing learning rate of group 0 to 1.0000e-04.\n",
      "================================================================\n",
      "Train Epoch: 13 [3358/3358 (100.00%)]  Accuracy: 64.41%  Loss: 0.7525\n",
      "Test set: Accuracy: 61.67%  Loss: 0.7626\n",
      "TP: 371, FP: 192, TN: 147, FN: 130\n",
      "Sensitivity: 0.7405, Specificity: 0.4336, F1-Score: 0.6974\n",
      "================================================================\n",
      "Train Epoch: 14 [3358/3358 (100.00%)]  Accuracy: 64.71%  Loss: 0.7505\n",
      "Test set: Accuracy: 61.31%  Loss: 0.7659\n",
      "TP: 340, FP: 164, TN: 175, FN: 161\n",
      "Sensitivity: 0.6786, Specificity: 0.5162, F1-Score: 0.6766\n",
      "================================================================\n",
      "Train Epoch: 15 [3358/3358 (100.00%)]  Accuracy: 63.19%  Loss: 0.7567\n",
      "Test set: Accuracy: 63.21%  Loss: 0.7594\n",
      "TP: 363, FP: 171, TN: 168, FN: 138\n",
      "Sensitivity: 0.7246, Specificity: 0.4956, F1-Score: 0.7014\n",
      "================================================================\n",
      "Train Epoch: 16 [3358/3358 (100.00%)]  Accuracy: 63.25%  Loss: 0.7546\n",
      "Test set: Accuracy: 60.24%  Loss: 0.7619\n",
      "TP: 327, FP: 160, TN: 179, FN: 174\n",
      "Sensitivity: 0.6527, Specificity: 0.5280, F1-Score: 0.6619\n",
      "================================================================\n",
      "Train Epoch: 17 [3358/3358 (100.00%)]  Accuracy: 63.73%  Loss: 0.7559\n",
      "Test set: Accuracy: 63.45%  Loss: 0.7575\n",
      "TP: 352, FP: 158, TN: 181, FN: 149\n",
      "Sensitivity: 0.7026, Specificity: 0.5339, F1-Score: 0.6963\n",
      "================================================================\n",
      "Train Epoch: 18 [3358/3358 (100.00%)]  Accuracy: 63.64%  Loss: 0.7546\n",
      "Test set: Accuracy: 62.14%  Loss: 0.7593\n",
      "TP: 343, FP: 160, TN: 179, FN: 158\n",
      "Sensitivity: 0.6846, Specificity: 0.5280, F1-Score: 0.6833\n",
      "================================================================\n",
      "Train Epoch: 19 [3358/3358 (100.00%)]  Accuracy: 64.26%  Loss: 0.7522\n",
      "Test set: Accuracy: 62.26%  Loss: 0.7568\n",
      "TP: 340, FP: 156, TN: 183, FN: 161\n",
      "Sensitivity: 0.6786, Specificity: 0.5398, F1-Score: 0.6820\n",
      "================================================================\n",
      "Train Epoch: 20 [3358/3358 (100.00%)]  Accuracy: 63.49%  Loss: 0.7528\n",
      "Test set: Accuracy: 61.79%  Loss: 0.7628\n",
      "TP: 343, FP: 163, TN: 176, FN: 158\n",
      "Sensitivity: 0.6846, Specificity: 0.5192, F1-Score: 0.6812\n",
      "================================================================\n",
      "Train Epoch: 21 [3358/3358 (100.00%)]  Accuracy: 63.34%  Loss: 0.7542\n",
      "Test set: Accuracy: 61.31%  Loss: 0.7603\n",
      "TP: 341, FP: 165, TN: 174, FN: 160\n",
      "Sensitivity: 0.6806, Specificity: 0.5133, F1-Score: 0.6773\n",
      "================================================================\n",
      "Train Epoch: 22 [3358/3358 (100.00%)]  Accuracy: 64.26%  Loss: 0.7529\n",
      "Test set: Accuracy: 60.71%  Loss: 0.7643\n",
      "TP: 334, FP: 163, TN: 176, FN: 167\n",
      "Sensitivity: 0.6667, Specificity: 0.5192, F1-Score: 0.6693\n",
      "================================================================\n",
      "Train Epoch: 23 [3358/3358 (100.00%)]  Accuracy: 63.73%  Loss: 0.7535\n",
      "Test set: Accuracy: 61.67%  Loss: 0.7586\n",
      "TP: 335, FP: 156, TN: 183, FN: 166\n",
      "Sensitivity: 0.6687, Specificity: 0.5398, F1-Score: 0.6754\n",
      "================================================================\n",
      "Train Epoch: 24 [3358/3358 (100.00%)]  Accuracy: 64.29%  Loss: 0.7530\n",
      "Test set: Accuracy: 60.83%  Loss: 0.7604\n",
      "TP: 328, FP: 156, TN: 183, FN: 173\n",
      "Sensitivity: 0.6547, Specificity: 0.5398, F1-Score: 0.6660\n",
      "================================================================\n",
      "Train Epoch: 25 [3358/3358 (100.00%)]  Accuracy: 64.18%  Loss: 0.7521\n",
      "Test set: Accuracy: 60.36%  Loss: 0.7624\n",
      "TP: 339, FP: 171, TN: 168, FN: 162\n",
      "Sensitivity: 0.6766, Specificity: 0.4956, F1-Score: 0.6706\n",
      "Epoch 00025: reducing learning rate of group 0 to 1.0000e-05.\n",
      "================================================================\n",
      "Train Epoch: 26 [3358/3358 (100.00%)]  Accuracy: 64.38%  Loss: 0.7503\n",
      "Test set: Accuracy: 62.26%  Loss: 0.7532\n",
      "TP: 339, FP: 155, TN: 184, FN: 162\n",
      "Sensitivity: 0.6766, Specificity: 0.5428, F1-Score: 0.6814\n",
      "================================================================\n",
      "Train Epoch: 27 [3358/3358 (100.00%)]  Accuracy: 64.09%  Loss: 0.7522\n",
      "Test set: Accuracy: 61.07%  Loss: 0.7618\n",
      "TP: 343, FP: 169, TN: 170, FN: 158\n",
      "Sensitivity: 0.6846, Specificity: 0.5015, F1-Score: 0.6772\n",
      "================================================================\n",
      "Train Epoch: 28 [3358/3358 (100.00%)]  Accuracy: 64.32%  Loss: 0.7520\n",
      "Test set: Accuracy: 60.71%  Loss: 0.7640\n",
      "TP: 337, FP: 166, TN: 173, FN: 164\n",
      "Sensitivity: 0.6727, Specificity: 0.5103, F1-Score: 0.6713\n",
      "================================================================\n",
      "Train Epoch: 29 [3358/3358 (100.00%)]  Accuracy: 64.15%  Loss: 0.7507\n",
      "Test set: Accuracy: 61.43%  Loss: 0.7589\n",
      "TP: 337, FP: 160, TN: 179, FN: 164\n",
      "Sensitivity: 0.6727, Specificity: 0.5280, F1-Score: 0.6754\n",
      "================================================================\n",
      "Train Epoch: 30 [3358/3358 (100.00%)]  Accuracy: 65.25%  Loss: 0.7481\n",
      "Test set: Accuracy: 63.10%  Loss: 0.7556\n",
      "TP: 355, FP: 164, TN: 175, FN: 146\n",
      "Sensitivity: 0.7086, Specificity: 0.5162, F1-Score: 0.6961\n",
      "================================================================\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 30+1):\n",
    "    train(model, train_dl, optimizer, epoch)\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    acc, loss, tp, fp, tn, fn = test(model, test_dl)\n",
    "    sensitivity, specificity, f1_score = getMetric(tp, fp, tn, fn)\n",
    "    print(f'TP: {tp}, FP: {fp}, TN: {tn}, FN: {fn}')\n",
    "    print(f'Sensitivity: {sensitivity:.4f}, Specificity: {specificity:.4f}, F1-Score: {f1_score:.4f}')\n",
    "\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_acc_model = deepcopy(model)\n",
    "        best_acc_model_state = deepcopy(model.state_dict())\n",
    "\n",
    "    if f1_score > best_f1:\n",
    "        best_f1 = f1_score\n",
    "        best_f1_model = deepcopy(model)\n",
    "        best_f1_model_state = deepcopy(model.state_dict())\n",
    "        \n",
    "    schedular.step(loss)\n",
    "    accs.append(acc)\n",
    "    losses.append(loss)\n",
    "\n",
    "    print('================================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b0ecc1aa-4bb1-4a2f-afec-574e8e654326",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_np = np.array(accs)\n",
    "losses_np = np.array(losses)\n",
    "np.save('./parameters/orig_acc_.npy', accs_np)\n",
    "np.save('./parameters/orig_loss_.npy', losses_np)\n",
    "\n",
    "torch.save(best_acc_model, './parameters/orig_best_acc_model_.pt')\n",
    "torch.save(best_acc_model_state, './parameters/orig_best_acc_model_state_.pt')\n",
    "torch.save(best_f1_model, './parameters/orig_best_f1_model_.pt')\n",
    "torch.save(best_f1_model_state, './parameters/orig_best_f1_model_state_.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
