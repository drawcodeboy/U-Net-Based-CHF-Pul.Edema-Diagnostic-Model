{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae863a34-6643-44fa-bc3a-bdb4860cd5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from PIL import ImageFilter\n",
    "from PIL import ImageOps\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from copy import copy\n",
    "from copy import deepcopy\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True' # dead kernel for matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b92c0ef-8d09-4b32-b143-5ce85b4f22c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4198 entries, 0 to 4197\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   subject_id      4198 non-null   int64 \n",
      " 1   study_id        4198 non-null   int64 \n",
      " 2   dicom_id        4198 non-null   object\n",
      " 3   DicomPath       4198 non-null   object\n",
      " 4   edema_severity  4198 non-null   int64 \n",
      " 5   normal          4198 non-null   int64 \n",
      " 6   CHF             4198 non-null   bool  \n",
      "dtypes: bool(1), int64(4), object(2)\n",
      "memory usage: 233.7+ KB\n"
     ]
    }
   ],
   "source": [
    "metadata = pd.read_csv('../doby_meta.csv')\n",
    "metadata = metadata[metadata['subject_id'] < 16000000]\n",
    "metadata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31517bce-30b5-4ee2-8a21-59ea06406329",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEG_BASE_PATH = '../chest-x-ray-dataset-with-lung-segmentation-1.0.0/chest-x-ray-dataset-with-lung-segmentation-1.0.0'\n",
    "ORIG_BASE_PATH = '../physionet.org/files/mimic-cxr-jpg/2.0.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90ba4915-2eb3-442f-b501-49d8a99c7a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resize(object):\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "\n",
    "    def __call__(self, x_seg, x_orig):\n",
    "        return x_seg, x_orig.resize((self.size, self.size))\n",
    "\n",
    "class MixImage(object):\n",
    "    def __call__(self, fore, back):\n",
    "        back.paste(fore, (0, 0), fore)\n",
    "        return back\n",
    "\n",
    "TRANSFORMS = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4702f83e-d0bc-40a2-b250-9fe04e6df31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, metadata, seg_base_path, transform=None):\n",
    "        self.metadata = metadata\n",
    "        self.seg_base_path = Path(seg_base_path)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x_path = self.metadata.loc[idx, 'DicomPath']\n",
    "        x_seg_path = self.seg_base_path / Path(x_path)\n",
    "        \n",
    "        x_seg = Image.open(x_seg_path).convert('L').resize((64, 64))\n",
    "\n",
    "        # 검은색 pixel이 많기 때문에 Histogram Equalization X\n",
    "        \n",
    "        y = self.metadata.loc[idx, 'normal']\n",
    "\n",
    "        if self.transform:\n",
    "            x = self.transform(x_seg)\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.metadata['normal'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c523295-c469-4d6e-85ae-9c36d8597333",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset(metadata, SEG_BASE_PATH, transform=TRANSFORMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0b89ffb-7f2c-4dca-9301-46c3f1a3157c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torchvision.transforms.functional import to_pil_image\n",
    "\n",
    "x, y = ds[201]\n",
    "plt.title(y)\n",
    "plt.imshow(to_pil_image(x), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "718f7151-5393-4321-ba8e-ff36f946bf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_size = len(ds)\n",
    "train_size = int(ds_size * 0.8)\n",
    "test_size = ds_size - train_size\n",
    "train_ds, test_ds = random_split(ds, [train_size, test_size], generator=torch.manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f5c1a73-e48a-43cd-a84a-c76c9aeffb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3358 840\n"
     ]
    }
   ],
   "source": [
    "print(len(train_ds), len(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0c93c66-b81e-43e0-bdaa-185366f7604c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = copy(train_ds)\n",
    "\n",
    "TRAIN_TRANSFORM = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # rotation degree = -10, 10\n",
    "    # translate -img_width * a < dx < img_width * a\n",
    "        # -11.2 < dx < 11.2, y도 b로 마찬가지, tuple 형태로\n",
    "    transforms.RandomAffine(degrees=10, translate=(0.05, 0.05))\n",
    "])\n",
    "\n",
    "train_ds.dataset.transform = TRAIN_TRANSFORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af7c9afb-52fa-45bc-b64a-ca38af213bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "test_dl = DataLoader(test_ds, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6821286c-61e7-41e2-abd0-eeabf120830e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CusVgg16(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CusVgg16, self).__init__()\n",
    "        self.vgg = models.vgg16(weights='IMAGENET1K_V1')\n",
    "        self.vgg.features[0] = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.vgg.classifier[6] = nn.Linear(4096, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.vgg(x)\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "910a2fe8-cf48-4239-84fb-705ce6cd43d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CusVgg16(\n",
       "  (vgg): VGG(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): ReLU(inplace=True)\n",
       "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (13): ReLU(inplace=True)\n",
       "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): ReLU(inplace=True)\n",
       "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (18): ReLU(inplace=True)\n",
       "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (20): ReLU(inplace=True)\n",
       "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (22): ReLU(inplace=True)\n",
       "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (25): ReLU(inplace=True)\n",
       "      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (27): ReLU(inplace=True)\n",
       "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (29): ReLU(inplace=True)\n",
       "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=4096, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = CusVgg16()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7581764a-ac5b-4b51-b7a0-5a642d95b1a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 vgg.features.0.weight\n",
      "1 vgg.features.0.bias\n",
      "2 vgg.features.2.weight\n",
      "3 vgg.features.2.bias\n",
      "4 vgg.features.5.weight\n",
      "5 vgg.features.5.bias\n",
      "6 vgg.features.7.weight\n",
      "7 vgg.features.7.bias\n",
      "8 vgg.features.10.weight\n",
      "9 vgg.features.10.bias\n",
      "10 vgg.features.12.weight\n",
      "11 vgg.features.12.bias\n",
      "12 vgg.features.14.weight\n",
      "13 vgg.features.14.bias\n",
      "14 vgg.features.17.weight\n",
      "15 vgg.features.17.bias\n",
      "16 vgg.features.19.weight\n",
      "17 vgg.features.19.bias\n",
      "18 vgg.features.21.weight\n",
      "19 vgg.features.21.bias\n",
      "20 vgg.features.24.weight\n",
      "21 vgg.features.24.bias\n",
      "22 vgg.features.26.weight\n",
      "23 vgg.features.26.bias\n",
      "24 vgg.features.28.weight\n",
      "25 vgg.features.28.bias\n",
      "26 vgg.classifier.0.weight\n",
      "27 vgg.classifier.0.bias\n",
      "28 vgg.classifier.3.weight\n",
      "29 vgg.classifier.3.bias\n",
      "30 vgg.classifier.6.weight\n",
      "31 vgg.classifier.6.bias\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for name, param in model.named_parameters():\n",
    "    print(i, name)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cab9f0a5-40f9-4cc7-bc89-375154d37487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requires_grad = True\n",
      "requires_grad = True\n",
      "requires_grad = True\n",
      "requires_grad = True\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for name, param in model.named_parameters():\n",
    "    if i == 0 or i == 1 or i == 30 or i == 31:\n",
    "        print('requires_grad = True')\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ff2d170-955f-4e64-be85-9feafb26dfb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(model.vgg.features[0].weight.requires_grad)\n",
    "print(model.vgg.features[0].bias.requires_grad)\n",
    "print(model.vgg.classifier[6].weight.requires_grad)\n",
    "print(model.vgg.classifier[6].bias.requires_grad)\n",
    "print(model.vgg.classifier[3].bias.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84df2ccc-0b1b-4f23-b5d5-a8ad4326e507",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "schedular = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "weights = (metadata['normal'] == 0).sum() / (metadata['normal'] == 1).sum()\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=torch.Tensor([weights])).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10ad465c-5bf8-41b4-a456-f6bd5a2fe1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    running_acc = 0\n",
    "    n_data = 0\n",
    "\n",
    "    for batch_idx, (batch, target) in enumerate(data_loader, start=1):\n",
    "        batch, target = batch.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(batch)\n",
    "        # print(output.shape, target.shape)\n",
    "        target_ = target\n",
    "        target = target.unsqueeze(dim=-1).float()\n",
    "\n",
    "        loss = loss_fn(output, target)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        predicted = (output >= torch.FloatTensor([0.5]).to(device)).type(torch.float32)\n",
    "        correct = (predicted == target).sum().item()\n",
    "        running_acc += correct\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        n_data += len(batch)\n",
    "        print(f'\\rTrain Epoch: {epoch} [{n_data}/{len(data_loader.dataset)} ({100 * batch_idx / len(data_loader):.2f}%)]  Accuracy: {100*running_acc/n_data:.2f}%  Loss: {running_loss/batch_idx:.4f}', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3808f73f-add2-431b-9eca-75f00acdf75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, data_loader):\n",
    "    model.eval()\n",
    "    test_acc = 0\n",
    "    test_loss = 0\n",
    "    n_data = 0\n",
    "    TP, FP, TN, FN = 0, 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch, target in data_loader:\n",
    "            batch, target = batch.to(device), target.to(device)\n",
    "\n",
    "            output = model(batch)\n",
    "            target = target.unsqueeze(dim=-1).float()\n",
    "\n",
    "            loss = loss_fn(output, target)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            predicted = (output >= torch.FloatTensor([0.5]).to(device)).type(torch.float32)\n",
    "            correct = (predicted == target).sum().item()\n",
    "            test_acc += correct\n",
    "\n",
    "            TP += ((predicted == target) & (target == 1)).sum().item()\n",
    "            FP += ((predicted != target) & (target == 0)).sum().item()\n",
    "            TN += ((predicted == target) & (target == 0)).sum().item()\n",
    "            FN += ((predicted != target) & (target == 1)).sum().item()\n",
    "            \n",
    "            n_data += len(batch)\n",
    "            print(f'\\rTest set: [{100*n_data/len(data_loader.dataset):.2f}%]', end='')\n",
    "    \n",
    "    test_acc = 100 * test_acc / len(data_loader.dataset)\n",
    "    test_loss = test_loss / len(data_loader)\n",
    "    \n",
    "    print(f'\\rTest set: Accuracy: {test_acc:.2f}%  Loss: {test_loss:.4f}')\n",
    "\n",
    "    return test_acc, test_loss, TP, FP, TN, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "962909b8-5b13-4534-a91c-36286985edc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMetric(TP, FP, TN, FN):\n",
    "    # base case: divide by zero\n",
    "    TP = 0.1 if TP == 0 else TP\n",
    "    FP = 0.1 if FP == 0 else FP\n",
    "    TN = 0.1 if TN == 0 else TN\n",
    "    FN = 0.1 if FN == 0 else FN\n",
    "    \n",
    "    sensitivity = TP/(TP+FN)\n",
    "    specificity = TN/(TN+FP)\n",
    "    precision = TP/(TP+FP)\n",
    "    recall = TP/(TP+FN)\n",
    "    f1_score = 2*precision*recall/(precision+recall)\n",
    "    return sensitivity, specificity, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "406f5f21-9ae0-4949-a020-02ec60aba9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = []\n",
    "losses = []\n",
    "best_acc = 0\n",
    "best_f1 = 0\n",
    "\n",
    "best_acc_model = None\n",
    "best_acc_model_state = None\n",
    "best_f1_model = None\n",
    "best_f1_model_state = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b133f06c-9641-4843-a51c-c653ac6e4fc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [3358/3358 (100.00%)]  Accuracy: 56.85%  Loss: 0.7928\n",
      "Test set: Accuracy: 55.12%  Loss: 0.7861\n",
      "TP: 188, FP: 64, TN: 275, FN: 313\n",
      "Sensitivity: 0.3752, Specificity: 0.8112, F1-Score: 0.4993\n",
      "================================================================\n",
      "Train Epoch: 2 [3358/3358 (100.00%)]  Accuracy: 60.33%  Loss: 0.7741\n",
      "Test set: Accuracy: 59.29%  Loss: 0.7698\n",
      "TP: 366, FP: 207, TN: 132, FN: 135\n",
      "Sensitivity: 0.7305, Specificity: 0.3894, F1-Score: 0.6816\n",
      "================================================================\n",
      "Train Epoch: 3 [3358/3358 (100.00%)]  Accuracy: 62.12%  Loss: 0.7640\n",
      "Test set: Accuracy: 61.19%  Loss: 0.7642\n",
      "TP: 303, FP: 128, TN: 211, FN: 198\n",
      "Sensitivity: 0.6048, Specificity: 0.6224, F1-Score: 0.6502\n",
      "================================================================\n",
      "Train Epoch: 4 [3358/3358 (100.00%)]  Accuracy: 61.11%  Loss: 0.7666\n",
      "Test set: Accuracy: 61.79%  Loss: 0.7613\n",
      "TP: 360, FP: 180, TN: 159, FN: 141\n",
      "Sensitivity: 0.7186, Specificity: 0.4690, F1-Score: 0.6916\n",
      "================================================================\n",
      "Train Epoch: 5 [3358/3358 (100.00%)]  Accuracy: 63.16%  Loss: 0.7587\n",
      "Test set: Accuracy: 59.29%  Loss: 0.7636\n",
      "TP: 331, FP: 172, TN: 167, FN: 170\n",
      "Sensitivity: 0.6607, Specificity: 0.4926, F1-Score: 0.6594\n",
      "================================================================\n",
      "Train Epoch: 6 [3358/3358 (100.00%)]  Accuracy: 63.40%  Loss: 0.7591\n",
      "Test set: Accuracy: 62.26%  Loss: 0.7629\n",
      "TP: 424, FP: 240, TN: 99, FN: 77\n",
      "Sensitivity: 0.8463, Specificity: 0.2920, F1-Score: 0.7279\n",
      "================================================================\n",
      "Train Epoch: 7 [3358/3358 (100.00%)]  Accuracy: 63.52%  Loss: 0.7551\n",
      "Test set: Accuracy: 62.62%  Loss: 0.7594\n",
      "TP: 368, FP: 181, TN: 158, FN: 133\n",
      "Sensitivity: 0.7345, Specificity: 0.4661, F1-Score: 0.7010\n",
      "================================================================\n",
      "Train Epoch: 8 [3358/3358 (100.00%)]  Accuracy: 63.13%  Loss: 0.7569\n",
      "Test set: Accuracy: 62.62%  Loss: 0.7588\n",
      "TP: 379, FP: 192, TN: 147, FN: 122\n",
      "Sensitivity: 0.7565, Specificity: 0.4336, F1-Score: 0.7071\n",
      "================================================================\n",
      "Train Epoch: 9 [3358/3358 (100.00%)]  Accuracy: 63.61%  Loss: 0.7564\n",
      "Test set: Accuracy: 62.02%  Loss: 0.7606\n",
      "TP: 358, FP: 176, TN: 163, FN: 143\n",
      "Sensitivity: 0.7146, Specificity: 0.4808, F1-Score: 0.6918\n",
      "================================================================\n",
      "Train Epoch: 10 [3358/3358 (100.00%)]  Accuracy: 62.89%  Loss: 0.7584\n",
      "Test set: Accuracy: 62.98%  Loss: 0.7609\n",
      "TP: 425, FP: 235, TN: 104, FN: 76\n",
      "Sensitivity: 0.8483, Specificity: 0.3068, F1-Score: 0.7321\n",
      "================================================================\n",
      "Train Epoch: 11 [3358/3358 (100.00%)]  Accuracy: 64.09%  Loss: 0.7529\n",
      "Test set: Accuracy: 60.48%  Loss: 0.7669\n",
      "TP: 267, FP: 98, TN: 241, FN: 234\n",
      "Sensitivity: 0.5329, Specificity: 0.7109, F1-Score: 0.6166\n",
      "================================================================\n",
      "Train Epoch: 12 [3358/3358 (100.00%)]  Accuracy: 63.88%  Loss: 0.7552\n",
      "Test set: Accuracy: 62.38%  Loss: 0.7626\n",
      "TP: 402, FP: 217, TN: 122, FN: 99\n",
      "Sensitivity: 0.8024, Specificity: 0.3599, F1-Score: 0.7179\n",
      "================================================================\n",
      "Train Epoch: 13 [3358/3358 (100.00%)]  Accuracy: 64.62%  Loss: 0.7537\n",
      "Test set: Accuracy: 62.02%  Loss: 0.7581\n",
      "TP: 358, FP: 176, TN: 163, FN: 143\n",
      "Sensitivity: 0.7146, Specificity: 0.4808, F1-Score: 0.6918\n",
      "================================================================\n",
      "Train Epoch: 14 [3358/3358 (100.00%)]  Accuracy: 64.65%  Loss: 0.7520\n",
      "Test set: Accuracy: 61.79%  Loss: 0.7588\n",
      "TP: 359, FP: 179, TN: 160, FN: 142\n",
      "Sensitivity: 0.7166, Specificity: 0.4720, F1-Score: 0.6910\n",
      "================================================================\n",
      "Train Epoch: 15 [3358/3358 (100.00%)]  Accuracy: 64.59%  Loss: 0.7508\n",
      "Test set: Accuracy: 61.31%  Loss: 0.7617\n",
      "TP: 362, FP: 186, TN: 153, FN: 139\n",
      "Sensitivity: 0.7226, Specificity: 0.4513, F1-Score: 0.6902\n",
      "================================================================\n",
      "Train Epoch: 16 [3358/3358 (100.00%)]  Accuracy: 64.74%  Loss: 0.7505\n",
      "Test set: Accuracy: 62.86%  Loss: 0.7555\n",
      "TP: 391, FP: 202, TN: 137, FN: 110\n",
      "Sensitivity: 0.7804, Specificity: 0.4041, F1-Score: 0.7148\n",
      "================================================================\n",
      "Train Epoch: 17 [3358/3358 (100.00%)]  Accuracy: 62.36%  Loss: 0.7585\n",
      "Test set: Accuracy: 64.40%  Loss: 0.7545\n",
      "TP: 428, FP: 226, TN: 113, FN: 73\n",
      "Sensitivity: 0.8543, Specificity: 0.3333, F1-Score: 0.7411\n",
      "================================================================\n",
      "Train Epoch: 18 [3358/3358 (100.00%)]  Accuracy: 64.56%  Loss: 0.7522\n",
      "Test set: Accuracy: 61.31%  Loss: 0.7567\n",
      "TP: 329, FP: 153, TN: 186, FN: 172\n",
      "Sensitivity: 0.6567, Specificity: 0.5487, F1-Score: 0.6694\n",
      "================================================================\n",
      "Train Epoch: 19 [3358/3358 (100.00%)]  Accuracy: 64.03%  Loss: 0.7539\n",
      "Test set: Accuracy: 62.26%  Loss: 0.7555\n",
      "TP: 314, FP: 130, TN: 209, FN: 187\n",
      "Sensitivity: 0.6267, Specificity: 0.6165, F1-Score: 0.6646\n",
      "================================================================\n",
      "Train Epoch: 20 [3358/3358 (100.00%)]  Accuracy: 62.42%  Loss: 0.7582\n",
      "Test set: Accuracy: 60.95%  Loss: 0.7565\n",
      "TP: 320, FP: 147, TN: 192, FN: 181\n",
      "Sensitivity: 0.6387, Specificity: 0.5664, F1-Score: 0.6612\n",
      "================================================================\n",
      "Train Epoch: 21 [3358/3358 (100.00%)]  Accuracy: 63.76%  Loss: 0.7518\n",
      "Test set: Accuracy: 61.90%  Loss: 0.7583\n",
      "TP: 334, FP: 153, TN: 186, FN: 167\n",
      "Sensitivity: 0.6667, Specificity: 0.5487, F1-Score: 0.6761\n",
      "================================================================\n",
      "Train Epoch: 22 [3358/3358 (100.00%)]  Accuracy: 65.16%  Loss: 0.7490\n",
      "Test set: Accuracy: 62.62%  Loss: 0.7552\n",
      "TP: 310, FP: 123, TN: 216, FN: 191\n",
      "Sensitivity: 0.6188, Specificity: 0.6372, F1-Score: 0.6638\n",
      "================================================================\n",
      "Train Epoch: 23 [3358/3358 (100.00%)]  Accuracy: 64.06%  Loss: 0.7516\n",
      "Test set: Accuracy: 63.81%  Loss: 0.7517\n",
      "TP: 389, FP: 192, TN: 147, FN: 112\n",
      "Sensitivity: 0.7764, Specificity: 0.4336, F1-Score: 0.7190\n",
      "================================================================\n",
      "Train Epoch: 24 [3358/3358 (100.00%)]  Accuracy: 64.47%  Loss: 0.7520\n",
      "Test set: Accuracy: 64.29%  Loss: 0.7505\n",
      "TP: 404, FP: 203, TN: 136, FN: 97\n",
      "Sensitivity: 0.8064, Specificity: 0.4012, F1-Score: 0.7292\n",
      "================================================================\n",
      "Train Epoch: 25 [3358/3358 (100.00%)]  Accuracy: 64.86%  Loss: 0.7498\n",
      "Test set: Accuracy: 64.52%  Loss: 0.7522\n",
      "TP: 427, FP: 224, TN: 115, FN: 74\n",
      "Sensitivity: 0.8523, Specificity: 0.3392, F1-Score: 0.7413\n",
      "================================================================\n",
      "Train Epoch: 26 [3358/3358 (100.00%)]  Accuracy: 63.46%  Loss: 0.7572\n",
      "Test set: Accuracy: 62.86%  Loss: 0.7578\n",
      "TP: 355, FP: 166, TN: 173, FN: 146\n",
      "Sensitivity: 0.7086, Specificity: 0.5103, F1-Score: 0.6947\n",
      "================================================================\n",
      "Train Epoch: 27 [3358/3358 (100.00%)]  Accuracy: 64.59%  Loss: 0.7492\n",
      "Test set: Accuracy: 63.81%  Loss: 0.7490\n",
      "TP: 345, FP: 148, TN: 191, FN: 156\n",
      "Sensitivity: 0.6886, Specificity: 0.5634, F1-Score: 0.6942\n",
      "================================================================\n",
      "Train Epoch: 28 [3358/3358 (100.00%)]  Accuracy: 64.44%  Loss: 0.7519\n",
      "Test set: Accuracy: 61.90%  Loss: 0.7555\n",
      "TP: 290, FP: 109, TN: 230, FN: 211\n",
      "Sensitivity: 0.5788, Specificity: 0.6785, F1-Score: 0.6444\n",
      "================================================================\n",
      "Train Epoch: 29 [3358/3358 (100.00%)]  Accuracy: 64.80%  Loss: 0.7507\n",
      "Test set: Accuracy: 64.29%  Loss: 0.7473\n",
      "TP: 353, FP: 152, TN: 187, FN: 148\n",
      "Sensitivity: 0.7046, Specificity: 0.5516, F1-Score: 0.7018\n",
      "================================================================\n",
      "Train Epoch: 30 [3358/3358 (100.00%)]  Accuracy: 64.47%  Loss: 0.7505\n",
      "Test set: Accuracy: 64.05%  Loss: 0.7476\n",
      "TP: 346, FP: 147, TN: 192, FN: 155\n",
      "Sensitivity: 0.6906, Specificity: 0.5664, F1-Score: 0.6962\n",
      "================================================================\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 30+1):\n",
    "    train(model, train_dl, optimizer, epoch)\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    acc, loss, tp, fp, tn, fn = test(model, test_dl)\n",
    "    sensitivity, specificity, f1_score = getMetric(tp, fp, tn, fn)\n",
    "    print(f'TP: {tp}, FP: {fp}, TN: {tn}, FN: {fn}')\n",
    "    print(f'Sensitivity: {sensitivity:.4f}, Specificity: {specificity:.4f}, F1-Score: {f1_score:.4f}')\n",
    "\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_acc_model = deepcopy(model)\n",
    "        best_acc_model_state = deepcopy(model.state_dict())\n",
    "\n",
    "    if f1_score > best_f1:\n",
    "        best_f1 = f1_score\n",
    "        best_f1_model = deepcopy(model)\n",
    "        best_f1_model_state = deepcopy(model.state_dict())\n",
    "        \n",
    "    schedular.step(loss)\n",
    "    accs.append(acc)\n",
    "    losses.append(loss)\n",
    "\n",
    "    print('================================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0001987a-1166-4936-af98-0ce84f96c334",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_np = np.array(accs)\n",
    "losses_np = np.array(losses)\n",
    "np.save('./parameters/seg_acc_.npy', accs_np)\n",
    "np.save('./parameters/seg_loss_.npy', losses_np)\n",
    "\n",
    "torch.save(best_acc_model, './parameters/seg_best_acc_model_.pt')\n",
    "torch.save(best_acc_model_state, './parameters/seg_best_acc_model_state_.pt')\n",
    "torch.save(best_f1_model, './parameters/seg_best_f1_model_.pt')\n",
    "torch.save(best_f1_model_state, './parameters/seg_best_f1_model_state_.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
