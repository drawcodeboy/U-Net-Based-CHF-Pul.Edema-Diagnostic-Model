{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "317cbdb6-ce99-467e-b106-f9172becd1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "import matplotlib.pyplot as plt\n",
    "from monai.losses import DiceLoss\n",
    "from PIL import Image\n",
    "from PIL import ImageFilter\n",
    "from PIL import ImageOps\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from copy import copy\n",
    "from copy import deepcopy\n",
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from pathlib import Path\n",
    "import math\n",
    "from Nested_UNet import Nested_UNet\n",
    "# from evaluation import *\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True' # dead kernel for matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "376e19b2-ced8-4fa2-b1fa-7fb86d97959a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef7e7542-ffd4-459f-8676-0f99cd46aaa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7064 entries, 0 to 7063\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   subject_id      7064 non-null   int64 \n",
      " 1   study_id        7064 non-null   int64 \n",
      " 2   dicom_id        7064 non-null   object\n",
      " 3   DicomPath       7064 non-null   object\n",
      " 4   edema_severity  7064 non-null   int64 \n",
      " 5   normal          7064 non-null   int64 \n",
      " 6   CHF             7064 non-null   bool  \n",
      "dtypes: bool(1), int64(4), object(2)\n",
      "memory usage: 338.2+ KB\n"
     ]
    }
   ],
   "source": [
    "metadata = pd.read_csv('../doby_meta.csv')\n",
    "metadata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df663e2f-0bff-4f30-8399-70be38d10243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4198 entries, 0 to 4197\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   subject_id      4198 non-null   int64 \n",
      " 1   study_id        4198 non-null   int64 \n",
      " 2   dicom_id        4198 non-null   object\n",
      " 3   DicomPath       4198 non-null   object\n",
      " 4   edema_severity  4198 non-null   int64 \n",
      " 5   normal          4198 non-null   int64 \n",
      " 6   CHF             4198 non-null   bool  \n",
      "dtypes: bool(1), int64(4), object(2)\n",
      "memory usage: 233.7+ KB\n"
     ]
    }
   ],
   "source": [
    "metadata = metadata[metadata['subject_id'] < 16000000]\n",
    "metadata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7625419-b54a-4da6-8488-7d730f2e1fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEG_BASE_PATH = '../chest-x-ray-dataset-with-lung-segmentation-1.0.0/chest-x-ray-dataset-with-lung-segmentation-1.0.0'\n",
    "ORIG_BASE_PATH = '../physionet.org/files/mimic-cxr-jpg/2.0.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "883a594f-929a-4ed3-a26c-bb7e07d45bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_TRANSFORMS = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "TARGET_TRANSFORMS = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c2f8f4b-961f-4546-a039-fc1983adf4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, metadata, mask_base_path, orig_base_path, transform=None, target_transform=None):\n",
    "        self.metadata = metadata\n",
    "        self.base_path = Path(orig_base_path)\n",
    "        self.mask_path = Path(mask_base_path)\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        detail_path = self.metadata.loc[idx, 'DicomPath']\n",
    "        y_path = self.mask_path / Path(str(detail_path[:-4]) + '-mask.jpg')\n",
    "        x_path = self.base_path / Path(str(detail_path))\n",
    "\n",
    "        y = Image.open(str(y_path))\n",
    "        x = cv2.imread(str(x_path), cv2.IMREAD_GRAYSCALE)\n",
    "        x = cv2.resize(x, dsize=(224, 224), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        del detail_path\n",
    "        del y_path\n",
    "        del x_path\n",
    "\n",
    "        # 이것 때문인지는 모르겠는데 ToTensor로 Normalize가 안 된다.\n",
    "        # y = np.where(y > 128, 255, 0) # 128 threshold\n",
    "        # y = np.where(y > 128, 255, 0) / 255.\n",
    "        \n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "\n",
    "        if self.target_transform:\n",
    "            y = self.target_transform(y)\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.metadata['normal'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf409e9f-2c5a-4ab2-b3b9-6b9d8c188980",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset(metadata, \n",
    "             SEG_BASE_PATH, \n",
    "             ORIG_BASE_PATH,\n",
    "             transform=TRAIN_TRANSFORMS,\n",
    "             target_transform=TARGET_TRANSFORMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d8d887d-470c-4503-a779-156e9f6250b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_size = len(ds)\n",
    "train_size = int(ds_size * 0.8)\n",
    "test_size = ds_size - train_size\n",
    "train_ds, test_ds = random_split(ds, [train_size, test_size], generator=torch.manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e655a798-43fc-4093-8a32-0ce8019bb083",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "test_dl = DataLoader(test_ds, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d3d0024-eaf8-4339-986a-829355f8d48b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Nested_UNet(\n",
       "  (x_0_0): EncoderBlock(\n",
       "    (convBlk): ConvBlock(\n",
       "      (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (x_1_0): EncoderBlock(\n",
       "    (convBlk): ConvBlock(\n",
       "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (x_2_0): EncoderBlock(\n",
       "    (convBlk): ConvBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (x_3_0): EncoderBlock(\n",
       "    (convBlk): ConvBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (x_4_0): EncoderBlock(\n",
       "    (convBlk): ConvBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (x_0_1): DecoderBlock(\n",
       "    (transposeConv): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (convBlk): ConvBlock(\n",
       "      (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (x_1_1): DecoderBlock(\n",
       "    (transposeConv): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (convBlk): ConvBlock(\n",
       "      (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (x_2_1): DecoderBlock(\n",
       "    (transposeConv): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (convBlk): ConvBlock(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (x_3_1): DecoderBlock(\n",
       "    (transposeConv): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (convBlk): ConvBlock(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (x_0_2): DecoderBlock(\n",
       "    (transposeConv): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (convBlk): ConvBlock(\n",
       "      (conv1): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (x_1_2): DecoderBlock(\n",
       "    (transposeConv): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (convBlk): ConvBlock(\n",
       "      (conv1): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (x_2_2): DecoderBlock(\n",
       "    (transposeConv): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (convBlk): ConvBlock(\n",
       "      (conv1): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (x_0_3): DecoderBlock(\n",
       "    (transposeConv): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (convBlk): ConvBlock(\n",
       "      (conv1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (x_1_3): DecoderBlock(\n",
       "    (transposeConv): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (convBlk): ConvBlock(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (x_0_4): DecoderBlock(\n",
       "    (transposeConv): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (convBlk): ConvBlock(\n",
       "      (conv1): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (convOut): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (acti): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Nested_UNet(channel=1, mode='fast') # feature size 10%\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f1b5bf8-7f7b-40d4-9398-64dc5e557aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "schedular = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "loss_fn = DiceLoss(reduction='mean').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c395c18d-1d30-4923-8f09-83e11aa66264",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    running_acc = 0\n",
    "    n_data = 0\n",
    "\n",
    "    for batch_idx, (batch, target) in enumerate(data_loader, start=1):\n",
    "        batch, target = batch.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(batch)\n",
    "        output_flat = output.view(output.size(0), -1)\n",
    "        target_flat = target.view(target.size(0), -1)\n",
    "\n",
    "        loss = loss_fn(output_flat, target_flat)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        output_flat = (output_flat >= torch.FloatTensor([0.5]).to(device)).type(torch.float32)\n",
    "        correct = (output_flat == target_flat).sum().item()\n",
    "        running_acc += correct\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Pixel 별 Accuracy\n",
    "        n_data += len(batch)\n",
    "        output_pixels = (output_flat.shape[1])\n",
    "        \n",
    "        print(f'\\rTrain Epoch: {epoch} [{n_data}/{len(data_loader.dataset)} ({100 * batch_idx / len(data_loader):.2f}%)]  Accuracy: {100*running_acc/(n_data*output_pixels):.2f}%  Loss: {running_loss/batch_idx:.4f}', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a689b4e-bd57-4334-8eb8-8b93e672dcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, data_loader):\n",
    "    model.eval()\n",
    "    test_acc = 0\n",
    "    test_loss = 0\n",
    "    n_data = 0\n",
    "    TP, FP, TN, FN = 0, 0, 0, 0\n",
    "    output_pixels = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch, target in data_loader:\n",
    "            batch, target = batch.to(device), target.to(device)\n",
    "\n",
    "            output = model(batch)\n",
    "\n",
    "            output_flat = output.view(output.size(0), -1)\n",
    "            target_flat = target.view(target.size(0), -1)\n",
    "\n",
    "            loss = loss_fn(output_flat, target_flat)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            output_flat = (output_flat >= torch.FloatTensor([0.5]).to(device)).type(torch.float32)\n",
    "\n",
    "            correct = (output_flat == target_flat).sum().item()\n",
    "            test_acc += correct\n",
    "\n",
    "            TP += ((output_flat == target_flat) & (target_flat == 1)).sum().item()\n",
    "            FP += ((output_flat != target_flat) & (target_flat == 0)).sum().item()\n",
    "            TN += ((output_flat == target_flat) & (target_flat == 0)).sum().item()\n",
    "            FN += ((output_flat != target_flat) & (target_flat == 1)).sum().item()\n",
    "            \n",
    "            n_data += len(batch)\n",
    "            output_pixels = (output_flat.shape[1])\n",
    "            \n",
    "            print(f'\\rTest set: [{100*n_data/len(data_loader.dataset):.2f}%]', end='')\n",
    "    \n",
    "    test_acc = 100 * test_acc / (len(data_loader.dataset)*output_pixels)\n",
    "    test_loss = test_loss / len(data_loader)\n",
    "    \n",
    "    print(f'\\rTest set: Accuracy: {test_acc:.2f}%  Loss: {test_loss:.4f}')\n",
    "\n",
    "    return test_acc, test_loss, TP, FP, TN, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9ff8a4d-3c28-4d51-91b9-0c36f79d8418",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMetric(TP, FP, TN, FN):\n",
    "    # base case: divide by zero\n",
    "    TP = 0.1 if TP == 0 else TP\n",
    "    FP = 0.1 if FP == 0 else FP\n",
    "    TN = 0.1 if TN == 0 else TN\n",
    "    FN = 0.1 if FN == 0 else FN\n",
    "    \n",
    "    sensitivity = TP/(TP+FN)\n",
    "    specificity = TN/(TN+FP)\n",
    "    precision = TP/(TP+FP)\n",
    "    recall = TP/(TP+FN)\n",
    "    f1_score = 2*precision*recall/(precision+recall)\n",
    "    mcc = ((TP*TN)-(FP*FN))/math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))\n",
    "    \n",
    "    return sensitivity, specificity, f1_score, mcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7e85aa3-f2da-4ea7-815a-68b7780345f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = []\n",
    "losses = []\n",
    "best_acc = 0\n",
    "best_f1 = 0\n",
    "\n",
    "best_acc_model = None\n",
    "best_acc_model_state = None\n",
    "best_f1_model = None\n",
    "best_f1_model_state = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4879d4cf-deb6-40ac-aa1e-e1c049e53491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [3358/3358 (100.00%)]  Accuracy: 88.64%  Loss: 0.1749\n",
      "Test set: Accuracy: 93.41%  Loss: 0.0652\n",
      "TP: 11176861, FP: 350530, TN: 28192676, FN: 634678\n",
      "Sensitivity: 0.9463, Specificity: 0.9877\n",
      "F1-Score: 0.9578, MCC: 0.9408\n",
      "================================================================\n",
      "Train Epoch: 2 [3358/3358 (100.00%)]  Accuracy: 93.82%  Loss: 0.0503\n",
      "Test set: Accuracy: 93.79%  Loss: 0.0473\n",
      "TP: 11179383, FP: 190561, TN: 28352645, FN: 632156\n",
      "Sensitivity: 0.9465, Specificity: 0.9933\n",
      "F1-Score: 0.9645, MCC: 0.9506\n",
      "================================================================\n",
      "Train Epoch: 3 [3358/3358 (100.00%)]  Accuracy: 94.14%  Loss: 0.0397\n",
      "Test set: Accuracy: 94.07%  Loss: 0.0395\n",
      "TP: 11295327, FP: 189782, TN: 28353424, FN: 516212\n",
      "Sensitivity: 0.9563, Specificity: 0.9934\n",
      "F1-Score: 0.9697, MCC: 0.9576\n",
      "================================================================\n",
      "Train Epoch: 4 [3358/3358 (100.00%)]  Accuracy: 94.27%  Loss: 0.0359\n",
      "Test set: Accuracy: 94.14%  Loss: 0.0370\n",
      "TP: 11382802, FP: 247612, TN: 28295594, FN: 428737\n",
      "Sensitivity: 0.9637, Specificity: 0.9913\n",
      "F1-Score: 0.9711, MCC: 0.9594\n",
      "================================================================\n",
      "Train Epoch: 5 [3358/3358 (100.00%)]  Accuracy: 94.40%  Loss: 0.0325\n",
      "Test set: Accuracy: 93.72%  Loss: 0.0432\n",
      "TP: 11602250, FP: 645065, TN: 27898141, FN: 209289\n",
      "Sensitivity: 0.9823, Specificity: 0.9774\n",
      "F1-Score: 0.9645, MCC: 0.9497\n",
      "================================================================\n",
      "Train Epoch: 6 [3358/3358 (100.00%)]  Accuracy: 94.50%  Loss: 0.0303\n",
      "Test set: Accuracy: 94.26%  Loss: 0.0332\n",
      "TP: 11499784, FP: 313782, TN: 28229424, FN: 311755\n",
      "Sensitivity: 0.9736, Specificity: 0.9890\n",
      "F1-Score: 0.9735, MCC: 0.9626\n",
      "================================================================\n",
      "Train Epoch: 7 [3358/3358 (100.00%)]  Accuracy: 94.56%  Loss: 0.0288\n",
      "Test set: Accuracy: 94.32%  Loss: 0.0324\n",
      "TP: 11487774, FP: 275204, TN: 28268002, FN: 323765\n",
      "Sensitivity: 0.9726, Specificity: 0.9904\n",
      "F1-Score: 0.9746, MCC: 0.9641\n",
      "================================================================\n",
      "Train Epoch: 8 [3358/3358 (100.00%)]  Accuracy: 94.64%  Loss: 0.0271\n",
      "Test set: Accuracy: 94.26%  Loss: 0.0334\n",
      "TP: 11384978, FP: 198250, TN: 28344956, FN: 426561\n",
      "Sensitivity: 0.9639, Specificity: 0.9931\n",
      "F1-Score: 0.9733, MCC: 0.9625\n",
      "================================================================\n",
      "Train Epoch: 9 [3358/3358 (100.00%)]  Accuracy: 94.72%  Loss: 0.0255\n",
      "Test set: Accuracy: 94.34%  Loss: 0.0311\n",
      "TP: 11567244, FP: 347276, TN: 28195930, FN: 244295\n",
      "Sensitivity: 0.9793, Specificity: 0.9878\n",
      "F1-Score: 0.9751, MCC: 0.9647\n",
      "================================================================\n",
      "Train Epoch: 10 [3358/3358 (100.00%)]  Accuracy: 94.78%  Loss: 0.0240\n",
      "Test set: Accuracy: 94.31%  Loss: 0.0318\n",
      "TP: 11597807, FP: 390214, TN: 28152992, FN: 213732\n",
      "Sensitivity: 0.9819, Specificity: 0.9863\n",
      "F1-Score: 0.9746, MCC: 0.9641\n",
      "================================================================\n",
      "Train Epoch: 11 [3358/3358 (100.00%)]  Accuracy: 94.79%  Loss: 0.0239\n",
      "Test set: Accuracy: 94.39%  Loss: 0.0304\n",
      "TP: 11553444, FP: 313336, TN: 28229870, FN: 258095\n",
      "Sensitivity: 0.9781, Specificity: 0.9890\n",
      "F1-Score: 0.9759, MCC: 0.9659\n",
      "================================================================\n",
      "Train Epoch: 12 [3358/3358 (100.00%)]  Accuracy: 94.88%  Loss: 0.0220\n",
      "Test set: Accuracy: 94.46%  Loss: 0.0292\n",
      "TP: 11472906, FP: 202073, TN: 28341133, FN: 338633\n",
      "Sensitivity: 0.9713, Specificity: 0.9929\n",
      "F1-Score: 0.9770, MCC: 0.9676\n",
      "================================================================\n",
      "Train Epoch: 13 [3358/3358 (100.00%)]  Accuracy: 94.92%  Loss: 0.0211\n",
      "Test set: Accuracy: 94.36%  Loss: 0.0310\n",
      "TP: 11426088, FP: 198123, TN: 28345083, FN: 385451\n",
      "Sensitivity: 0.9674, Specificity: 0.9931\n",
      "F1-Score: 0.9751, MCC: 0.9650\n",
      "================================================================\n",
      "Train Epoch: 14 [3358/3358 (100.00%)]  Accuracy: 94.93%  Loss: 0.0208\n",
      "Test set: Accuracy: 94.38%  Loss: 0.0303\n",
      "TP: 11586704, FP: 350856, TN: 28192350, FN: 224835\n",
      "Sensitivity: 0.9810, Specificity: 0.9877\n",
      "F1-Score: 0.9758, MCC: 0.9657\n",
      "================================================================\n",
      "Train Epoch: 15 [3358/3358 (100.00%)]  Accuracy: 95.01%  Loss: 0.0190\n",
      "Test set: Accuracy: 94.45%  Loss: 0.0294\n",
      "TP: 11424671, FP: 157300, TN: 28385906, FN: 386868\n",
      "Sensitivity: 0.9672, Specificity: 0.9945\n",
      "F1-Score: 0.9767, MCC: 0.9673\n",
      "================================================================\n",
      "Train Epoch: 16 [3358/3358 (100.00%)]  Accuracy: 95.02%  Loss: 0.0188\n",
      "Test set: Accuracy: 94.40%  Loss: 0.0303\n",
      "TP: 11425419, FP: 181295, TN: 28361911, FN: 386120\n",
      "Sensitivity: 0.9673, Specificity: 0.9936\n",
      "F1-Score: 0.9758, MCC: 0.9659\n",
      "================================================================\n",
      "Train Epoch: 17 [3358/3358 (100.00%)]  Accuracy: 95.06%  Loss: 0.0180\n",
      "Test set: Accuracy: 94.53%  Loss: 0.0275\n",
      "TP: 11521823, FP: 221094, TN: 28322112, FN: 289716\n",
      "Sensitivity: 0.9755, Specificity: 0.9923\n",
      "F1-Score: 0.9783, MCC: 0.9694\n",
      "================================================================\n",
      "Train Epoch: 18 [3358/3358 (100.00%)]  Accuracy: 95.10%  Loss: 0.0170\n",
      "Test set: Accuracy: 94.46%  Loss: 0.0286\n",
      "TP: 11569752, FP: 299819, TN: 28243387, FN: 241787\n",
      "Sensitivity: 0.9795, Specificity: 0.9895\n",
      "F1-Score: 0.9771, MCC: 0.9676\n",
      "================================================================\n",
      "Train Epoch: 19 [3358/3358 (100.00%)]  Accuracy: 95.11%  Loss: 0.0169\n",
      "Test set: Accuracy: 94.38%  Loss: 0.0309\n",
      "TP: 11375058, FP: 140321, TN: 28402885, FN: 436481\n",
      "Sensitivity: 0.9630, Specificity: 0.9951\n",
      "F1-Score: 0.9753, MCC: 0.9654\n",
      "================================================================\n",
      "Train Epoch: 20 [3358/3358 (100.00%)]  Accuracy: 95.12%  Loss: 0.0167\n",
      "Test set: Accuracy: 94.54%  Loss: 0.0271\n",
      "TP: 11553086, FP: 249625, TN: 28293581, FN: 258453\n",
      "Sensitivity: 0.9781, Specificity: 0.9913\n",
      "F1-Score: 0.9785, MCC: 0.9696\n",
      "================================================================\n",
      "Train Epoch: 21 [3358/3358 (100.00%)]  Accuracy: 95.16%  Loss: 0.0157\n",
      "Test set: Accuracy: 94.49%  Loss: 0.0282\n",
      "TP: 11499528, FP: 215672, TN: 28327534, FN: 312011\n",
      "Sensitivity: 0.9736, Specificity: 0.9924\n",
      "F1-Score: 0.9776, MCC: 0.9684\n",
      "================================================================\n",
      "Train Epoch: 22 [3358/3358 (100.00%)]  Accuracy: 95.18%  Loss: 0.0152\n",
      "Test set: Accuracy: 94.37%  Loss: 0.0305\n",
      "TP: 11566540, FP: 335720, TN: 28207486, FN: 244999\n",
      "Sensitivity: 0.9793, Specificity: 0.9882\n",
      "F1-Score: 0.9755, MCC: 0.9653\n",
      "================================================================\n",
      "Train Epoch: 23 [3358/3358 (100.00%)]  Accuracy: 95.15%  Loss: 0.0159\n",
      "Test set: Accuracy: 94.42%  Loss: 0.0294\n",
      "TP: 11532074, FP: 277488, TN: 28265718, FN: 279465\n",
      "Sensitivity: 0.9763, Specificity: 0.9903\n",
      "F1-Score: 0.9764, MCC: 0.9667\n",
      "================================================================\n",
      "Train Epoch: 24 [3358/3358 (100.00%)]  Accuracy: 95.18%  Loss: 0.0151\n",
      "Test set: Accuracy: 94.49%  Loss: 0.0279\n",
      "TP: 11518056, FP: 234724, TN: 28308482, FN: 293483\n",
      "Sensitivity: 0.9752, Specificity: 0.9918\n",
      "F1-Score: 0.9776, MCC: 0.9683\n",
      "================================================================\n",
      "Train Epoch: 25 [3358/3358 (100.00%)]  Accuracy: 95.24%  Loss: 0.0139\n",
      "Test set: Accuracy: 94.54%  Loss: 0.0271\n",
      "TP: 11560321, FP: 258970, TN: 28284236, FN: 251218\n",
      "Sensitivity: 0.9787, Specificity: 0.9909\n",
      "F1-Score: 0.9784, MCC: 0.9695\n",
      "================================================================\n",
      "Train Epoch: 26 [3358/3358 (100.00%)]  Accuracy: 95.26%  Loss: 0.0135\n",
      "Test set: Accuracy: 94.54%  Loss: 0.0273\n",
      "TP: 11510423, FP: 208351, TN: 28334855, FN: 301116\n",
      "Sensitivity: 0.9745, Specificity: 0.9927\n",
      "F1-Score: 0.9783, MCC: 0.9695\n",
      "================================================================\n",
      "Train Epoch: 27 [3358/3358 (100.00%)]  Accuracy: 95.28%  Loss: 0.0131\n",
      "Test set: Accuracy: 94.52%  Loss: 0.0274\n",
      "TP: 11592787, FP: 298589, TN: 28244617, FN: 218752\n",
      "Sensitivity: 0.9815, Specificity: 0.9895\n",
      "F1-Score: 0.9782, MCC: 0.9691\n",
      "================================================================\n",
      "Train Epoch: 28 [3358/3358 (100.00%)]  Accuracy: 95.28%  Loss: 0.0130\n",
      "Test set: Accuracy: 94.52%  Loss: 0.0276\n",
      "TP: 11483907, FP: 188679, TN: 28354527, FN: 327632\n",
      "Sensitivity: 0.9723, Specificity: 0.9934\n",
      "F1-Score: 0.9780, MCC: 0.9690\n",
      "================================================================\n",
      "Train Epoch: 29 [3358/3358 (100.00%)]  Accuracy: 95.27%  Loss: 0.0132\n",
      "Test set: Accuracy: 94.51%  Loss: 0.0278\n",
      "TP: 11474564, FP: 185719, TN: 28357487, FN: 336975\n",
      "Sensitivity: 0.9715, Specificity: 0.9935\n",
      "F1-Score: 0.9777, MCC: 0.9686\n",
      "================================================================\n",
      "Train Epoch: 30 [3358/3358 (100.00%)]  Accuracy: 95.29%  Loss: 0.0127\n",
      "Test set: Accuracy: 94.54%  Loss: 0.0271\n",
      "TP: 11514962, FP: 213087, TN: 28330119, FN: 296577\n",
      "Sensitivity: 0.9749, Specificity: 0.9925\n",
      "F1-Score: 0.9783, MCC: 0.9694\n",
      "================================================================\n",
      "Train Epoch: 31 [3358/3358 (100.00%)]  Accuracy: 95.31%  Loss: 0.0123\n",
      "Test set: Accuracy: 94.54%  Loss: 0.0272\n",
      "TP: 11525413, FP: 223227, TN: 28319979, FN: 286126\n",
      "Sensitivity: 0.9758, Specificity: 0.9922\n",
      "F1-Score: 0.9784, MCC: 0.9695\n",
      "================================================================\n",
      "Train Epoch: 32 [3358/3358 (100.00%)]  Accuracy: 95.31%  Loss: 0.0123\n",
      "Test set: Accuracy: 94.56%  Loss: 0.0268\n",
      "TP: 11527344, FP: 216642, TN: 28326564, FN: 284195\n",
      "Sensitivity: 0.9759, Specificity: 0.9924\n",
      "F1-Score: 0.9787, MCC: 0.9700\n",
      "================================================================\n",
      "Train Epoch: 33 [3358/3358 (100.00%)]  Accuracy: 95.33%  Loss: 0.0118\n",
      "Test set: Accuracy: 94.51%  Loss: 0.0277\n",
      "TP: 11529414, FP: 239540, TN: 28303666, FN: 282125\n",
      "Sensitivity: 0.9761, Specificity: 0.9916\n",
      "F1-Score: 0.9779, MCC: 0.9687\n",
      "================================================================\n",
      "Train Epoch: 34 [3358/3358 (100.00%)]  Accuracy: 95.34%  Loss: 0.0116\n",
      "Test set: Accuracy: 94.46%  Loss: 0.0290\n",
      "TP: 11428423, FP: 160220, TN: 28382986, FN: 383116\n",
      "Sensitivity: 0.9676, Specificity: 0.9944\n",
      "F1-Score: 0.9768, MCC: 0.9674\n",
      "================================================================\n",
      "Train Epoch: 35 [3358/3358 (100.00%)]  Accuracy: 95.34%  Loss: 0.0116\n",
      "Test set: Accuracy: 94.52%  Loss: 0.0276\n",
      "TP: 11504117, FP: 210720, TN: 28332486, FN: 307422\n",
      "Sensitivity: 0.9740, Specificity: 0.9926\n",
      "F1-Score: 0.9780, MCC: 0.9689\n",
      "================================================================\n",
      "Train Epoch: 36 [3358/3358 (100.00%)]  Accuracy: 95.35%  Loss: 0.0112\n",
      "Test set: Accuracy: 94.54%  Loss: 0.0271\n",
      "TP: 11515582, FP: 210414, TN: 28332792, FN: 295957\n",
      "Sensitivity: 0.9749, Specificity: 0.9926\n",
      "F1-Score: 0.9785, MCC: 0.9696\n",
      "================================================================\n",
      "Train Epoch: 37 [3358/3358 (100.00%)]  Accuracy: 95.35%  Loss: 0.0113\n",
      "Test set: Accuracy: 94.58%  Loss: 0.0264\n",
      "TP: 11537950, FP: 219416, TN: 28323790, FN: 273589\n",
      "Sensitivity: 0.9768, Specificity: 0.9923\n",
      "F1-Score: 0.9791, MCC: 0.9705\n",
      "================================================================\n",
      "Train Epoch: 38 [3358/3358 (100.00%)]  Accuracy: 95.36%  Loss: 0.0111\n",
      "Test set: Accuracy: 94.55%  Loss: 0.0268\n",
      "TP: 11548795, FP: 242743, TN: 28300463, FN: 262744\n",
      "Sensitivity: 0.9778, Specificity: 0.9915\n",
      "F1-Score: 0.9786, MCC: 0.9697\n",
      "================================================================\n",
      "Train Epoch: 39 [3358/3358 (100.00%)]  Accuracy: 95.37%  Loss: 0.0108\n",
      "Test set: Accuracy: 94.52%  Loss: 0.0273\n",
      "TP: 11498608, FP: 202025, TN: 28341181, FN: 312931\n",
      "Sensitivity: 0.9735, Specificity: 0.9929\n",
      "F1-Score: 0.9781, MCC: 0.9691\n",
      "================================================================\n",
      "Train Epoch: 40 [3358/3358 (100.00%)]  Accuracy: 95.38%  Loss: 0.0105\n",
      "Test set: Accuracy: 94.56%  Loss: 0.0266\n",
      "TP: 11556156, FP: 243758, TN: 28299448, FN: 255383\n",
      "Sensitivity: 0.9784, Specificity: 0.9915\n",
      "F1-Score: 0.9789, MCC: 0.9701\n",
      "================================================================\n",
      "Train Epoch: 41 [3358/3358 (100.00%)]  Accuracy: 95.39%  Loss: 0.0104\n",
      "Test set: Accuracy: 94.51%  Loss: 0.0277\n",
      "TP: 11480974, FP: 190012, TN: 28353194, FN: 330565\n",
      "Sensitivity: 0.9720, Specificity: 0.9933\n",
      "F1-Score: 0.9778, MCC: 0.9688\n",
      "================================================================\n",
      "Train Epoch: 42 [3358/3358 (100.00%)]  Accuracy: 95.39%  Loss: 0.0104\n",
      "Test set: Accuracy: 94.53%  Loss: 0.0272\n",
      "TP: 11526647, FP: 227054, TN: 28316152, FN: 284892\n",
      "Sensitivity: 0.9759, Specificity: 0.9920\n",
      "F1-Score: 0.9783, MCC: 0.9693\n",
      "================================================================\n",
      "Train Epoch: 43 [3358/3358 (100.00%)]  Accuracy: 95.39%  Loss: 0.0103\n",
      "Test set: Accuracy: 94.45%  Loss: 0.0290\n",
      "TP: 11455880, FP: 189922, TN: 28353284, FN: 355659\n",
      "Sensitivity: 0.9699, Specificity: 0.9933\n",
      "F1-Score: 0.9767, MCC: 0.9673\n",
      "Epoch 00043: reducing learning rate of group 0 to 1.0000e-05.\n",
      "================================================================\n",
      "Train Epoch: 44 [3358/3358 (100.00%)]  Accuracy: 95.46%  Loss: 0.0088\n",
      "Test set: Accuracy: 94.58%  Loss: 0.0262\n",
      "TP: 11512034, FP: 191130, TN: 28352076, FN: 299505\n",
      "Sensitivity: 0.9746, Specificity: 0.9933\n",
      "F1-Score: 0.9791, MCC: 0.9706\n",
      "================================================================\n",
      "Train Epoch: 45 [3358/3358 (100.00%)]  Accuracy: 95.49%  Loss: 0.0080\n",
      "Test set: Accuracy: 94.60%  Loss: 0.0259\n",
      "TP: 11537337, FP: 209268, TN: 28333938, FN: 274202\n",
      "Sensitivity: 0.9768, Specificity: 0.9927\n",
      "F1-Score: 0.9795, MCC: 0.9710\n",
      "================================================================\n",
      "Train Epoch: 46 [3358/3358 (100.00%)]  Accuracy: 95.51%  Loss: 0.0076\n",
      "Test set: Accuracy: 94.60%  Loss: 0.0258\n",
      "TP: 11530318, FP: 203398, TN: 28339808, FN: 281221\n",
      "Sensitivity: 0.9762, Specificity: 0.9929\n",
      "F1-Score: 0.9794, MCC: 0.9710\n",
      "================================================================\n",
      "Train Epoch: 47 [3358/3358 (100.00%)]  Accuracy: 95.52%  Loss: 0.0073\n",
      "Test set: Accuracy: 94.59%  Loss: 0.0259\n",
      "TP: 11521497, FP: 194979, TN: 28348227, FN: 290042\n",
      "Sensitivity: 0.9754, Specificity: 0.9932\n",
      "F1-Score: 0.9794, MCC: 0.9709\n",
      "================================================================\n",
      "Train Epoch: 48 [3358/3358 (100.00%)]  Accuracy: 95.53%  Loss: 0.0071\n",
      "Test set: Accuracy: 94.60%  Loss: 0.0259\n",
      "TP: 11526621, FP: 198681, TN: 28344525, FN: 284918\n",
      "Sensitivity: 0.9759, Specificity: 0.9930\n",
      "F1-Score: 0.9795, MCC: 0.9710\n",
      "================================================================\n",
      "Train Epoch: 49 [3358/3358 (100.00%)]  Accuracy: 95.54%  Loss: 0.0069\n",
      "Test set: Accuracy: 94.60%  Loss: 0.0258\n",
      "TP: 11526290, FP: 197226, TN: 28345980, FN: 285249\n",
      "Sensitivity: 0.9758, Specificity: 0.9931\n",
      "F1-Score: 0.9795, MCC: 0.9711\n",
      "================================================================\n",
      "Train Epoch: 50 [3358/3358 (100.00%)]  Accuracy: 95.55%  Loss: 0.0068\n",
      "Test set: Accuracy: 94.60%  Loss: 0.0259\n",
      "TP: 11519310, FP: 192513, TN: 28350693, FN: 292229\n",
      "Sensitivity: 0.9753, Specificity: 0.9933\n",
      "F1-Score: 0.9794, MCC: 0.9709\n",
      "================================================================\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 50+1):\n",
    "    train(model, train_dl, optimizer, epoch)\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    acc, loss, tp, fp, tn, fn = test(model, test_dl)\n",
    "    sensitivity, specificity, f1_score, mcc = getMetric(tp, fp, tn, fn)\n",
    "    print(f'TP: {tp}, FP: {fp}, TN: {tn}, FN: {fn}')\n",
    "    print(f'Sensitivity: {sensitivity:.4f}, Specificity: {specificity:.4f}\\nF1-Score: {f1_score:.4f}, MCC: {mcc:.4f}')\n",
    "\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_acc_model = deepcopy(model)\n",
    "        best_acc_model_state = deepcopy(model.state_dict())\n",
    "\n",
    "    if f1_score > best_f1:\n",
    "        best_f1 = f1_score\n",
    "        best_f1_model = deepcopy(model)\n",
    "        best_f1_model_state = deepcopy(model.state_dict())\n",
    "        \n",
    "    schedular.step(loss)\n",
    "    accs.append(acc)\n",
    "    losses.append(loss)\n",
    "\n",
    "    print('================================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b22127c-8686-47b1-affc-d286b1e7d98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_np = np.array(accs)\n",
    "losses_np = np.array(losses)\n",
    "np.save('./nested_unet_fast_acc.npy', accs_np)\n",
    "np.save('./nested_unet_fast_loss.npy', losses_np)\n",
    "\n",
    "torch.save(best_acc_model, './nested_unet_fast_best_acc_model.pt')\n",
    "torch.save(best_acc_model_state, './nested_unet_fast_best_acc_model_state.pt')\n",
    "torch.save(best_f1_model, './nested_unet_fast_best_f1_model.pt')\n",
    "torch.save(best_f1_model_state, './nested_unet_fast_best_f1_model_state.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
